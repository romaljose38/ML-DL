{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maping(x):\n",
    "    return x*5 + 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    x = np.random.randn(2,)\n",
    "    y = sum(list(map(maping, x)))\n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, x, weight,  bias):\n",
    "        self.x = x\n",
    "        self.bias = bias\n",
    "        self.weight = weight\n",
    "\n",
    "    \n",
    "    def get_output(self):\n",
    "        val = self.x * self.weight + self.bias\n",
    "        return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self, input, y, activation):\n",
    "        self.input = input\n",
    "        self.y = y\n",
    "        self.activation = activation\n",
    "        self.weights = np.random.random(len(self.input))\n",
    "        self.bias = np.random.random()\n",
    "    \n",
    "    def output(self):\n",
    "\n",
    "        y_cal = []\n",
    "        \n",
    "        for tensor in self.input:\n",
    "            sum = 0\n",
    "            for idx, val in enumerate(tensor):\n",
    "                p = Perceptron(x=val, weight=self.weights[idx], bias=self.bias)\n",
    "                sum+=p.get_output()\n",
    "            y_cal.append(sum)\n",
    "        \n",
    "        self.y_est = y_cal\n",
    "\n",
    "        return self.y_est\n",
    "\n",
    "    def cal_loss(self):\n",
    "        loss = list(map(lambda x: (x[0]-x[1])**2, zip(self.y_est, self.y)))\n",
    "        \n",
    "        self.cur_loss = loss\n",
    "\n",
    "        return sum(loss)/len(loss)\n",
    "\n",
    "\n",
    "    def propagation(self, step=0.5):\n",
    "\n",
    "        for val in self.input:\n",
    "            \n",
    "            loss = sum(list(map(lambda x: (x[0]-x[1]), zip(self.y_est, self.y))))\n",
    "        \n",
    "            changes = []           \n",
    "            \n",
    "            for idx in range(len(self.y)):\n",
    "                derv = (2*loss/len(self.y_est))*val[idx]\n",
    "                \n",
    "                if derv>0:\n",
    "                    changes.append(self.weights[idx]-(step))\n",
    "                else:\n",
    "                    changes.append(self.weights[idx]+(step))\n",
    "            \n",
    "\n",
    "            self.weights=changes\n",
    "\n",
    "            self.output()\n",
    "            self.cal_loss()        \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Layer(input=X, y=Y,activation=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([29.84255893, 34.94584907]),\n",
       " array([22.47059648, 28.77065657]),\n",
       " array([29.03618689, 44.8374386 ]),\n",
       " array([33.23995035, 28.25234893]),\n",
       " array([31.08758299, 33.68683873]),\n",
       " array([32.32484426, 25.98304686]),\n",
       " array([35.17505853, 28.96753015]),\n",
       " array([43.22052916, 25.77696891]),\n",
       " array([34.47759733, 20.43932279]),\n",
       " array([34.71750609, 34.99195013]),\n",
       " array([22.4425264 , 25.53822002]),\n",
       " array([35.54363823, 32.23811405]),\n",
       " array([20.59185565, 32.74007199]),\n",
       " array([24.38172166, 28.27813325]),\n",
       " array([34.89670019, 20.64036836]),\n",
       " array([35.17226506, 25.3483057 ]),\n",
       " array([41.83108649, 42.86756898]),\n",
       " array([35.1830061 , 32.74657493]),\n",
       " array([30.48888288, 32.1389411 ]),\n",
       " array([38.9537821, 39.3554329]),\n",
       " array([17.41775418, 28.89634955]),\n",
       " array([35.97398277, 41.53471385]),\n",
       " array([34.15933855, 30.36591865]),\n",
       " array([41.98037158, 33.07278598]),\n",
       " array([27.32809992, 37.34725007]),\n",
       " array([19.55473479, 30.51750928]),\n",
       " array([30.31840615, 33.9541832 ]),\n",
       " array([30.33571812, 21.97481567]),\n",
       " array([30.18149392, 35.71008939]),\n",
       " array([40.60521723, 35.12245851]),\n",
       " array([29.80143191, 45.20898439]),\n",
       " array([18.36529239, 29.89606122]),\n",
       " array([24.88968807, 36.80717384]),\n",
       " array([30.94778854, 21.91936018]),\n",
       " array([26.91270056, 31.56753536]),\n",
       " array([34.19915208, 26.6462273 ]),\n",
       " array([35.03650086, 29.55087082]),\n",
       " array([28.44295135, 37.14782711]),\n",
       " array([38.09593365, 26.03517377]),\n",
       " array([27.96754036, 26.88289856]),\n",
       " array([45.50433907, 37.6284397 ]),\n",
       " array([27.50401633, 31.01921292]),\n",
       " array([34.74764953, 29.6438256 ]),\n",
       " array([27.92074875, 27.77704334]),\n",
       " array([24.23045675, 39.18258541]),\n",
       " array([38.31955504, 31.13185315]),\n",
       " array([24.70995685, 29.77324658]),\n",
       " array([30.50113739, 30.2305331 ]),\n",
       " array([40.15601063, 33.2259436 ]),\n",
       " array([27.89161858, 26.88936797]),\n",
       " array([34.75546692, 28.55205089]),\n",
       " array([25.35559475, 27.34801377]),\n",
       " array([27.89696014, 34.25957173]),\n",
       " array([25.98519792, 35.10836485]),\n",
       " array([41.70455094, 37.33903895]),\n",
       " array([35.87873573, 41.03016015]),\n",
       " array([40.9078328 , 34.87144963]),\n",
       " array([40.86717838, 40.50857067]),\n",
       " array([28.78142853, 32.14576719]),\n",
       " array([28.61925312, 30.38281722]),\n",
       " array([28.19224161, 25.41343999]),\n",
       " array([29.38300521, 34.41748435]),\n",
       " array([36.25193559, 29.21144465]),\n",
       " array([29.07887775, 47.24039803]),\n",
       " array([30.74292523, 34.45266761]),\n",
       " array([19.2754155 , 38.60071022]),\n",
       " array([28.23565819, 32.33037187]),\n",
       " array([25.25778101, 41.41475112]),\n",
       " array([23.94457642, 19.28809165]),\n",
       " array([28.73980793, 28.4018537 ]),\n",
       " array([33.0899011 , 25.15470631]),\n",
       " array([29.37919473, 32.75084653]),\n",
       " array([34.77771221, 24.73840695]),\n",
       " array([34.33364303, 30.17777203]),\n",
       " array([35.7935098 , 30.29489612]),\n",
       " array([36.54313425, 23.63126474]),\n",
       " array([34.01779338, 35.3452086 ]),\n",
       " array([29.3083731 , 21.91216557]),\n",
       " array([34.20895247, 32.49835939]),\n",
       " array([40.15849175, 28.92378883]),\n",
       " array([32.72566012, 23.68849015]),\n",
       " array([35.3313434 , 29.80249482]),\n",
       " array([21.7145235 , 26.17299827]),\n",
       " array([30.12412205, 27.97219701]),\n",
       " array([35.52704877, 26.85065208]),\n",
       " array([29.54689322, 31.02630791]),\n",
       " array([24.44148918, 38.85126186]),\n",
       " array([32.3283961 , 38.79352711]),\n",
       " array([26.16226794, 21.04682427]),\n",
       " array([34.96656553, 39.05172035]),\n",
       " array([31.08168681, 28.02040151]),\n",
       " array([39.17827915, 22.63055289]),\n",
       " array([32.84810823, 41.11085225]),\n",
       " array([27.01493141, 22.59387371]),\n",
       " array([27.30345188, 35.50028947]),\n",
       " array([32.46131881, 31.92542327]),\n",
       " array([34.15174051, 24.7711732 ]),\n",
       " array([23.54624319, 34.64848256]),\n",
       " array([38.18122393, 22.63720241]),\n",
       " array([25.99312779, 35.38410555])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([761725.42795124, 761749.43895011])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.cal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91012959, 0.59226224, 0.74928778, 0.83899609, 0.05520719,\n",
       "       0.9133319 , 0.55845509, 0.10028459, 0.24890669, 0.47647284,\n",
       "       0.81039613, 0.7908475 , 0.12353587, 0.79143478, 0.77687775,\n",
       "       0.49186068, 0.73938988, 0.31124588, 0.50431016, 0.94692539,\n",
       "       0.61768124, 0.56474745, 0.69367905, 0.52749667, 0.61242885,\n",
       "       0.37968772, 0.47304373, 0.87664926, 0.8576567 , 0.00512053,\n",
       "       0.46961651, 0.34999319, 0.26059769, 0.07496218, 0.4216445 ,\n",
       "       0.02208588, 0.89109474, 0.58723768, 0.9553459 , 0.78400555,\n",
       "       0.38502478, 0.00213854, 0.91446898, 0.11046031, 0.05981254,\n",
       "       0.36515945, 0.11661766, 0.38804727, 0.56859358, 0.71501368,\n",
       "       0.16763468, 0.21009597, 0.56590158, 0.48359679, 0.06031138,\n",
       "       0.11121219, 0.82764017, 0.58201447, 0.52151119, 0.7907643 ,\n",
       "       0.05737247, 0.96630006, 0.07419539, 0.68680323, 0.43774594,\n",
       "       0.0598026 , 0.45965936, 0.99613964, 0.64495932, 0.85329139,\n",
       "       0.54988146, 0.59743013, 0.06395496, 0.76396124, 0.69912095,\n",
       "       0.16373588, 0.47493604, 0.08426612, 0.29186594, 0.50768547,\n",
       "       0.90332341, 0.33581281, 0.3103164 , 0.56965946, 0.22923697,\n",
       "       0.829132  , 0.22615517, 0.93483593, 0.33940372, 0.8875228 ,\n",
       "       0.90806703, 0.43342449, 0.6787892 , 0.27430232, 0.90284742,\n",
       "       0.84715175, 0.23673585, 0.82075571, 0.4232004 , 0.03039571])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ml1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 44\u001b[0m, in \u001b[0;36mLayer.propagation\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)):\n\u001b[0;32m     42\u001b[0m     derv \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mloss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_est))\u001b[38;5;241m*\u001b[39mval[idx]\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mderv\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[0;32m     45\u001b[0m         changes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[idx]\u001b[38;5;241m-\u001b[39m(step))\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "l1.propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92380986.11569908"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.cal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630394001.6952511"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.cal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 0\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    l1.propagation()\n",
    "\n",
    "    loss = l1.cal_loss()\n",
    "\n",
    "    if min<loss:\n",
    "        min = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073279300.1111346"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    step = trial.suggest_float(\"step\", 0.1, 1, step=0.05)\n",
    "    l1.propagation(step=step)\n",
    "    loss = l1.cal_loss()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 23:09:28,819]\u001b[0m A new study created in memory with name: no-name-0b9df0b9-e3f5-412a-b9d8-19b809158d46\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:29,508]\u001b[0m Trial 0 finished with value: 390902303.87756324 and parameters: {'step': 0.85}. Best is trial 0 with value: 390902303.87756324.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:30,205]\u001b[0m Trial 1 finished with value: 1611584.1175215137 and parameters: {'step': 0.45000000000000007}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:30,890]\u001b[0m Trial 2 finished with value: 26046988.91219394 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:31,574]\u001b[0m Trial 3 finished with value: 7576981.207246948 and parameters: {'step': 0.15000000000000002}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:32,265]\u001b[0m Trial 4 finished with value: 15287016.730882114 and parameters: {'step': 0.85}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:32,951]\u001b[0m Trial 5 finished with value: 39307862.88485852 and parameters: {'step': 0.4}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:33,639]\u001b[0m Trial 6 finished with value: 128852521.64401124 and parameters: {'step': 0.8}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:34,323]\u001b[0m Trial 7 finished with value: 284626961.62541103 and parameters: {'step': 0.85}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:35,003]\u001b[0m Trial 8 finished with value: 263372495.70985165 and parameters: {'step': 0.7000000000000001}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:35,702]\u001b[0m Trial 9 finished with value: 41747417.1318382 and parameters: {'step': 0.35}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:36,401]\u001b[0m Trial 10 finished with value: 90342274.30475588 and parameters: {'step': 0.55}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:37,080]\u001b[0m Trial 11 finished with value: 32939608.158374798 and parameters: {'step': 0.1}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:37,759]\u001b[0m Trial 12 finished with value: 31666733.484426595 and parameters: {'step': 0.1}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:38,450]\u001b[0m Trial 13 finished with value: 30353147.276981983 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:39,120]\u001b[0m Trial 14 finished with value: 49624564.39999594 and parameters: {'step': 0.55}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:39,808]\u001b[0m Trial 15 finished with value: 150988343.21693704 and parameters: {'step': 1.0}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:40,491]\u001b[0m Trial 16 finished with value: 52564791.70702527 and parameters: {'step': 0.25}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:41,187]\u001b[0m Trial 17 finished with value: 53434854.0810011 and parameters: {'step': 0.4}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:41,880]\u001b[0m Trial 18 finished with value: 59181157.47078929 and parameters: {'step': 0.2}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:42,573]\u001b[0m Trial 19 finished with value: 88678205.79725981 and parameters: {'step': 0.5}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:43,261]\u001b[0m Trial 20 finished with value: 159340480.51987144 and parameters: {'step': 0.65}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:43,946]\u001b[0m Trial 21 finished with value: 339384895.9888121 and parameters: {'step': 1.0}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:44,619]\u001b[0m Trial 22 finished with value: 105699036.73285037 and parameters: {'step': 0.2}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:45,306]\u001b[0m Trial 23 finished with value: 96794061.59868336 and parameters: {'step': 0.45000000000000007}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:45,982]\u001b[0m Trial 24 finished with value: 110076210.65275715 and parameters: {'step': 0.65}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:46,658]\u001b[0m Trial 25 finished with value: 191421507.13760358 and parameters: {'step': 0.9}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:47,334]\u001b[0m Trial 26 finished with value: 124811957.65407497 and parameters: {'step': 0.2}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:48,015]\u001b[0m Trial 27 finished with value: 154482294.14190614 and parameters: {'step': 0.6}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:48,709]\u001b[0m Trial 28 finished with value: 180453172.8821883 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:49,388]\u001b[0m Trial 29 finished with value: 305056646.36063486 and parameters: {'step': 0.9}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:50,060]\u001b[0m Trial 30 finished with value: 249670169.8647951 and parameters: {'step': 0.45000000000000007}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:50,746]\u001b[0m Trial 31 finished with value: 204556962.54918328 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:51,439]\u001b[0m Trial 32 finished with value: 182928484.7435714 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:52,122]\u001b[0m Trial 33 finished with value: 194464466.20880696 and parameters: {'step': 0.85}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:52,803]\u001b[0m Trial 34 finished with value: 254113794.64351228 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:53,478]\u001b[0m Trial 35 finished with value: 389892889.99435866 and parameters: {'step': 0.9}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:54,169]\u001b[0m Trial 36 finished with value: 513768854.34986573 and parameters: {'step': 0.65}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:54,845]\u001b[0m Trial 37 finished with value: 402439343.44855744 and parameters: {'step': 0.9500000000000001}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:55,521]\u001b[0m Trial 38 finished with value: 337913617.54177123 and parameters: {'step': 0.8}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:56,203]\u001b[0m Trial 39 finished with value: 300108294.98858523 and parameters: {'step': 0.8}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:56,884]\u001b[0m Trial 40 finished with value: 288947718.6305477 and parameters: {'step': 0.7000000000000001}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:57,564]\u001b[0m Trial 41 finished with value: 293104366.93319654 and parameters: {'step': 0.35}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:58,247]\u001b[0m Trial 42 finished with value: 307163311.4738788 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:58,949]\u001b[0m Trial 43 finished with value: 308641123.937515 and parameters: {'step': 0.1}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:59,630]\u001b[0m Trial 44 finished with value: 308964207.3825221 and parameters: {'step': 0.4}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:00,310]\u001b[0m Trial 45 finished with value: 321194044.22028494 and parameters: {'step': 0.25}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:00,990]\u001b[0m Trial 46 finished with value: 329876290.8600259 and parameters: {'step': 0.15000000000000002}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:01,666]\u001b[0m Trial 47 finished with value: 372867596.42649615 and parameters: {'step': 0.5}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:02,359]\u001b[0m Trial 48 finished with value: 400762746.2766291 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:03,036]\u001b[0m Trial 49 finished with value: 353901294.0313941 and parameters: {'step': 0.15000000000000002}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tuner = optuna.create_study(direction=\"minimize\")\n",
    "tuner.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125240,\n",
       " 133500,\n",
       " 129895,\n",
       " 127875,\n",
       " 142695,\n",
       " 136525,\n",
       " 127665,\n",
       " 123250,\n",
       " 133905,\n",
       " 122060,\n",
       " 126120,\n",
       " 133695,\n",
       " 110430,\n",
       " 135155,\n",
       " 113275,\n",
       " 120765,\n",
       " 121165,\n",
       " 121400,\n",
       " 123540,\n",
       " 124010,\n",
       " 126645,\n",
       " 131780,\n",
       " 138985,\n",
       " 131990,\n",
       " 140235,\n",
       " 122460,\n",
       " 128535,\n",
       " 131940,\n",
       " 114565,\n",
       " 126205,\n",
       " 131450,\n",
       " 128650,\n",
       " 118015,\n",
       " 131580,\n",
       " 125565,\n",
       " 139580,\n",
       " 131870,\n",
       " 121490,\n",
       " 118830,\n",
       " 131050,\n",
       " 126810,\n",
       " 111705,\n",
       " 132955,\n",
       " 125880,\n",
       " 114820,\n",
       " 119090,\n",
       " 126510,\n",
       " 113440,\n",
       " 135910,\n",
       " 123155,\n",
       " 140720,\n",
       " 115115,\n",
       " 129670,\n",
       " 126970,\n",
       " 131990,\n",
       " 125120,\n",
       " 115540,\n",
       " 119095,\n",
       " 126640,\n",
       " 124995,\n",
       " 121260,\n",
       " 107900,\n",
       " 132590,\n",
       " 118025,\n",
       " 123860,\n",
       " 125510,\n",
       " 123765,\n",
       " 132690,\n",
       " 118635,\n",
       " 132965,\n",
       " 133575,\n",
       " 130035,\n",
       " 121235,\n",
       " 126965,\n",
       " 118060,\n",
       " 116865,\n",
       " 117995,\n",
       " 119815,\n",
       " 136915,\n",
       " 112260,\n",
       " 127940,\n",
       " 128915,\n",
       " 124565,\n",
       " 122525,\n",
       " 122675,\n",
       " 127740,\n",
       " 117130,\n",
       " 136805,\n",
       " 120660,\n",
       " 117525,\n",
       " 134455,\n",
       " 122045,\n",
       " 132250,\n",
       " 122360,\n",
       " 137515,\n",
       " 119425,\n",
       " 134305,\n",
       " 133675,\n",
       " 128895,\n",
       " 116445]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01057901486696921"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1611584**(1/2))/120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(10,100,size=(1000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 77, 75, 25, 88, 27, 36, 97, 93, 33])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.random.rand(10)\n",
    "params = params.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.dot(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0 \n",
    "\n",
    "for i in range(len(X[0])):\n",
    "    sum += X[0][i]*params[i]\n",
    "sum.round(8)==Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308.53999999999996\n",
      "<built-in function sum>\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    W1 = np.random.rand(10,10).round(2)\n",
    "    b1 = np.random.rand()\n",
    "    W2 = np.random.rand(10,1)\n",
    "    b2 = np.random.rand()\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def forward_propagation(W1, b1, W2, b2, X):\n",
    "    O1 = X.dot(W1.T)+b1\n",
    "    O2 = O1.dot(W2) + b2\n",
    "    return O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = forward_propagation(W1,b1,W2,b2, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(W1, b1, W2, b2):\n",
    "    Y_pred = forward_propagation(W1,b1,W2,b2,X)\n",
    "    return (abs(Y_pred-Y).sum()/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y =np.reshape(Y,(1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(W1, b1, W2, b2, X, alpha):\n",
    "    Y_pred = forward_propagation(W1,b1,W2,b2,X)\n",
    "    loss = (Y_pred-Y)/1000\n",
    "    cur_loss = get_loss(W1,b1,W2,b2)\n",
    "    O1 = X.dot(W1.T)+b1\n",
    "    O2 = O1.dot(W2) + b2\n",
    "    dW2 = (2/1000)*(O1.T.dot(loss))\n",
    "    dW1 = (2/1000)*np.dot(W2,loss.T).dot(X)\n",
    "\n",
    "    db2 = loss.sum()/1000\n",
    "    db1 = ((2/1000)*W2.dot(loss.T)).sum()/1000\n",
    "    \n",
    "    # print(dW2,dW1)\n",
    "\n",
    "    W1 = W1 - alpha*(dW1.T)\n",
    "    W2 = W2 - alpha*dW2\n",
    "    b1 = b1 - alpha*db1\n",
    "    b2 = b2 - alpha*db2\n",
    "\n",
    "    return W1, W2, b1, b2\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778897.2249909608\n"
     ]
    }
   ],
   "source": [
    "cur_loss = get_loss(W1,b1,W2,b2)\n",
    "print(cur_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New low loss found \n",
      " Iteration: 0, Loss: 675525.7357413027\n",
      "New low loss found \n",
      " Iteration: 1, Loss: 665627.6385585408\n",
      "New low loss found \n",
      " Iteration: 2, Loss: 654744.5481205417\n",
      "New low loss found \n",
      " Iteration: 3, Loss: 689651.2029015257\n",
      "New low loss found \n",
      " Iteration: 4, Loss: 686377.9301065665\n",
      "New low loss found \n",
      " Iteration: 5, Loss: 709002.2893385437\n",
      "New low loss found \n",
      " Iteration: 6, Loss: 649462.7203259568\n",
      "New low loss found \n",
      " Iteration: 7, Loss: 612342.5080420817\n",
      "New low loss found \n",
      " Iteration: 8, Loss: 577625.1217297161\n",
      "New low loss found \n",
      " Iteration: 9, Loss: 571908.2236827547\n",
      "New low loss found \n",
      " Iteration: 10, Loss: 586816.3762635065\n",
      "New low loss found \n",
      " Iteration: 11, Loss: 631205.9274787662\n",
      "New low loss found \n",
      " Iteration: 12, Loss: 604285.3606476516\n",
      "New low loss found \n",
      " Iteration: 13, Loss: 572768.0018225296\n",
      "New low loss found \n",
      " Iteration: 14, Loss: 644828.9294193482\n",
      "New low loss found \n",
      " Iteration: 15, Loss: 724515.8027564081\n",
      "New low loss found \n",
      " Iteration: 16, Loss: 690304.8315543401\n",
      "New low loss found \n",
      " Iteration: 17, Loss: 704880.1567251501\n",
      "New low loss found \n",
      " Iteration: 18, Loss: 719904.465021559\n",
      "New low loss found \n",
      " Iteration: 19, Loss: 671799.7425250598\n",
      "New low loss found \n",
      " Iteration: 20, Loss: 675780.4540308638\n",
      "New low loss found \n",
      " Iteration: 21, Loss: 724091.3419693069\n",
      "New low loss found \n",
      " Iteration: 22, Loss: 775037.9230988785\n",
      "New low loss found \n",
      " Iteration: 23, Loss: 747999.5925173614\n",
      "New low loss found \n",
      " Iteration: 25, Loss: 673298.6337316867\n",
      "New low loss found \n",
      " Iteration: 26, Loss: 700950.1247221325\n",
      "New low loss found \n",
      " Iteration: 27, Loss: 623436.5974263326\n",
      "New low loss found \n",
      " Iteration: 28, Loss: 600605.8499580738\n",
      "New low loss found \n",
      " Iteration: 29, Loss: 611945.6621200118\n",
      "New low loss found \n",
      " Iteration: 30, Loss: 582771.0748934242\n",
      "New low loss found \n",
      " Iteration: 31, Loss: 562637.2286805449\n",
      "New low loss found \n",
      " Iteration: 32, Loss: 569949.1563003346\n",
      "New low loss found \n",
      " Iteration: 33, Loss: 634391.7194611428\n",
      "New low loss found \n",
      " Iteration: 34, Loss: 644896.3728375192\n",
      "New low loss found \n",
      " Iteration: 35, Loss: 596314.3626293134\n",
      "New low loss found \n",
      " Iteration: 36, Loss: 545332.1490819583\n",
      "New low loss found \n",
      " Iteration: 37, Loss: 514649.09896360006\n",
      "New low loss found \n",
      " Iteration: 38, Loss: 522890.2002626272\n",
      "New low loss found \n",
      " Iteration: 39, Loss: 560880.0239781969\n",
      "New low loss found \n",
      " Iteration: 40, Loss: 553809.6185760471\n",
      "New low loss found \n",
      " Iteration: 41, Loss: 599108.6903125944\n",
      "New low loss found \n",
      " Iteration: 42, Loss: 602601.4161806743\n",
      "New low loss found \n",
      " Iteration: 43, Loss: 590184.9705326526\n",
      "New low loss found \n",
      " Iteration: 44, Loss: 663230.2852242381\n",
      "New low loss found \n",
      " Iteration: 45, Loss: 702046.8752755424\n",
      "New low loss found \n",
      " Iteration: 46, Loss: 722134.0496814796\n",
      "New low loss found \n",
      " Iteration: 47, Loss: 720845.006787452\n",
      "New low loss found \n",
      " Iteration: 48, Loss: 701009.9801175776\n",
      "New low loss found \n",
      " Iteration: 49, Loss: 631574.4677139213\n",
      "New low loss found \n",
      " Iteration: 50, Loss: 673619.2448815991\n",
      "New low loss found \n",
      " Iteration: 51, Loss: 696662.8589394202\n",
      "New low loss found \n",
      " Iteration: 52, Loss: 646904.7718100554\n",
      "New low loss found \n",
      " Iteration: 53, Loss: 695768.8678433157\n",
      "New low loss found \n",
      " Iteration: 55, Loss: 615333.6871029749\n",
      "New low loss found \n",
      " Iteration: 56, Loss: 605601.3451016071\n",
      "New low loss found \n",
      " Iteration: 57, Loss: 652726.0159642542\n",
      "New low loss found \n",
      " Iteration: 58, Loss: 634249.8714926796\n",
      "New low loss found \n",
      " Iteration: 59, Loss: 578274.885709316\n",
      "New low loss found \n",
      " Iteration: 60, Loss: 582147.8863296204\n",
      "New low loss found \n",
      " Iteration: 61, Loss: 540833.267003001\n",
      "New low loss found \n",
      " Iteration: 62, Loss: 521384.890202542\n",
      "New low loss found \n",
      " Iteration: 63, Loss: 569334.0722823616\n",
      "New low loss found \n",
      " Iteration: 64, Loss: 505926.4628706441\n",
      "New low loss found \n",
      " Iteration: 65, Loss: 576652.196252819\n",
      "New low loss found \n",
      " Iteration: 66, Loss: 561813.2000267335\n",
      "New low loss found \n",
      " Iteration: 67, Loss: 486678.4437482237\n",
      "New low loss found \n",
      " Iteration: 68, Loss: 547148.356471234\n",
      "New low loss found \n",
      " Iteration: 69, Loss: 576328.3164902589\n",
      "New low loss found \n",
      " Iteration: 70, Loss: 628263.9386830822\n",
      "New low loss found \n",
      " Iteration: 71, Loss: 608612.3454950167\n",
      "New low loss found \n",
      " Iteration: 72, Loss: 600497.1612381069\n",
      "New low loss found \n",
      " Iteration: 73, Loss: 496420.9158630722\n",
      "New low loss found \n",
      " Iteration: 74, Loss: 554915.5190544615\n",
      "New low loss found \n",
      " Iteration: 75, Loss: 498901.50454803073\n",
      "New low loss found \n",
      " Iteration: 76, Loss: 589083.9965387507\n",
      "New low loss found \n",
      " Iteration: 77, Loss: 550162.919699232\n",
      "New low loss found \n",
      " Iteration: 78, Loss: 652605.3895897153\n",
      "New low loss found \n",
      " Iteration: 79, Loss: 685516.6645815391\n",
      "New low loss found \n",
      " Iteration: 80, Loss: 675043.1364307711\n",
      "New low loss found \n",
      " Iteration: 81, Loss: 707604.2542810501\n",
      "New low loss found \n",
      " Iteration: 82, Loss: 727444.2932047428\n",
      "New low loss found \n",
      " Iteration: 83, Loss: 715300.1717175562\n",
      "New low loss found \n",
      " Iteration: 85, Loss: 684015.4956000976\n",
      "New low loss found \n",
      " Iteration: 86, Loss: 701327.8712391976\n",
      "New low loss found \n",
      " Iteration: 87, Loss: 746318.2365098466\n",
      "New low loss found \n",
      " Iteration: 88, Loss: 757356.029223042\n",
      "New low loss found \n",
      " Iteration: 90, Loss: 725146.9167386662\n",
      "New low loss found \n",
      " Iteration: 91, Loss: 746752.8779972654\n",
      "New low loss found \n",
      " Iteration: 92, Loss: 694417.097988448\n",
      "New low loss found \n",
      " Iteration: 93, Loss: 740723.49340139\n",
      "New low loss found \n",
      " Iteration: 94, Loss: 738520.7947468768\n",
      "New low loss found \n",
      " Iteration: 95, Loss: 693676.0462791302\n",
      "New low loss found \n",
      " Iteration: 96, Loss: 663705.3631468015\n",
      "New low loss found \n",
      " Iteration: 97, Loss: 757840.445828259\n",
      "New low loss found \n",
      " Iteration: 99, Loss: 723606.072143056\n",
      "New low loss found \n",
      " Iteration: 100, Loss: 738332.3413794929\n",
      "New low loss found \n",
      " Iteration: 101, Loss: 765041.1748825788\n",
      "New low loss found \n",
      " Iteration: 103, Loss: 714035.304915398\n",
      "New low loss found \n",
      " Iteration: 104, Loss: 710829.5543252648\n",
      "New low loss found \n",
      " Iteration: 106, Loss: 700194.6122053437\n",
      "New low loss found \n",
      " Iteration: 107, Loss: 681112.7323704918\n",
      "New low loss found \n",
      " Iteration: 108, Loss: 737240.839151696\n",
      "New low loss found \n",
      " Iteration: 114, Loss: 732750.9336061693\n",
      "New low loss found \n",
      " Iteration: 115, Loss: 713843.6950799483\n",
      "New low loss found \n",
      " Iteration: 116, Loss: 763078.050621885\n",
      "New low loss found \n",
      " Iteration: 117, Loss: 716854.57567199\n",
      "New low loss found \n",
      " Iteration: 118, Loss: 733072.2524097918\n",
      "New low loss found \n",
      " Iteration: 119, Loss: 665839.0645347498\n",
      "New low loss found \n",
      " Iteration: 120, Loss: 699777.7561848285\n",
      "New low loss found \n",
      " Iteration: 121, Loss: 666137.4118214768\n",
      "New low loss found \n",
      " Iteration: 122, Loss: 711168.029821279\n",
      "New low loss found \n",
      " Iteration: 123, Loss: 699426.7090342161\n",
      "New low loss found \n",
      " Iteration: 124, Loss: 687708.3158009762\n",
      "New low loss found \n",
      " Iteration: 125, Loss: 736615.5595751812\n",
      "New low loss found \n",
      " Iteration: 126, Loss: 757802.1199168827\n",
      "New low loss found \n",
      " Iteration: 128, Loss: 704005.3196192773\n",
      "New low loss found \n",
      " Iteration: 129, Loss: 709339.1004126148\n",
      "New low loss found \n",
      " Iteration: 130, Loss: 714457.3668416081\n",
      "New low loss found \n",
      " Iteration: 132, Loss: 751880.4327015559\n",
      "New low loss found \n",
      " Iteration: 133, Loss: 762483.9699336917\n",
      "New low loss found \n",
      " Iteration: 134, Loss: 725082.3551827847\n",
      "New low loss found \n",
      " Iteration: 135, Loss: 674402.2227011862\n",
      "New low loss found \n",
      " Iteration: 136, Loss: 723539.2155344513\n",
      "New low loss found \n",
      " Iteration: 137, Loss: 742326.3494222325\n",
      "New low loss found \n",
      " Iteration: 138, Loss: 734832.3382229942\n",
      "New low loss found \n",
      " Iteration: 140, Loss: 755274.646133698\n",
      "New low loss found \n",
      " Iteration: 142, Loss: 739248.8546557714\n",
      "New low loss found \n",
      " Iteration: 144, Loss: 627116.886688214\n",
      "New low loss found \n",
      " Iteration: 145, Loss: 602627.2397828178\n",
      "New low loss found \n",
      " Iteration: 146, Loss: 557123.0395598786\n",
      "New low loss found \n",
      " Iteration: 147, Loss: 483304.89342335315\n",
      "New low loss found \n",
      " Iteration: 148, Loss: 478989.1555606954\n",
      "New low loss found \n",
      " Iteration: 149, Loss: 482477.90924577543\n",
      "New low loss found \n",
      " Iteration: 150, Loss: 389701.47920394875\n",
      "New low loss found \n",
      " Iteration: 151, Loss: 314616.97733726405\n",
      "New low loss found \n",
      " Iteration: 152, Loss: 362251.33047695644\n",
      "New low loss found \n",
      " Iteration: 153, Loss: 272785.18018447584\n",
      "New low loss found \n",
      " Iteration: 154, Loss: 375353.6492031921\n",
      "New low loss found \n",
      " Iteration: 155, Loss: 324241.3580370228\n",
      "New low loss found \n",
      " Iteration: 156, Loss: 310940.88597069733\n",
      "New low loss found \n",
      " Iteration: 157, Loss: 321949.66701795126\n",
      "New low loss found \n",
      " Iteration: 158, Loss: 253288.8741443128\n",
      "New low loss found \n",
      " Iteration: 159, Loss: 257977.79868769454\n",
      "New low loss found \n",
      " Iteration: 160, Loss: 258499.22895430357\n",
      "New low loss found \n",
      " Iteration: 161, Loss: 244460.89914843472\n",
      "New low loss found \n",
      " Iteration: 162, Loss: 201634.3887487587\n",
      "New low loss found \n",
      " Iteration: 163, Loss: 205745.20446810737\n",
      "New low loss found \n",
      " Iteration: 164, Loss: 242337.77190942946\n",
      "New low loss found \n",
      " Iteration: 165, Loss: 221261.26098500896\n",
      "New low loss found \n",
      " Iteration: 166, Loss: 201419.22715484345\n",
      "New low loss found \n",
      " Iteration: 167, Loss: 205074.0136139094\n",
      "New low loss found \n",
      " Iteration: 168, Loss: 201248.6745416369\n",
      "New low loss found \n",
      " Iteration: 169, Loss: 154317.5713169894\n",
      "New low loss found \n",
      " Iteration: 170, Loss: 183136.30793442327\n",
      "New low loss found \n",
      " Iteration: 171, Loss: 158242.06974858296\n",
      "New low loss found \n",
      " Iteration: 172, Loss: 183560.49526518592\n",
      "New low loss found \n",
      " Iteration: 173, Loss: 196280.46622709508\n",
      "New low loss found \n",
      " Iteration: 174, Loss: 161400.65025844195\n",
      "New low loss found \n",
      " Iteration: 175, Loss: 148944.50338381017\n",
      "New low loss found \n",
      " Iteration: 176, Loss: 142101.6207702103\n",
      "New low loss found \n",
      " Iteration: 177, Loss: 166708.89776498682\n",
      "New low loss found \n",
      " Iteration: 178, Loss: 148507.21185518324\n",
      "New low loss found \n",
      " Iteration: 179, Loss: 148009.95387280497\n",
      "New low loss found \n",
      " Iteration: 180, Loss: 143740.93754992154\n",
      "New low loss found \n",
      " Iteration: 181, Loss: 151773.88638131157\n",
      "New low loss found \n",
      " Iteration: 182, Loss: 144396.3438438501\n",
      "New low loss found \n",
      " Iteration: 183, Loss: 160425.8330998078\n",
      "New low loss found \n",
      " Iteration: 184, Loss: 155655.37205492996\n",
      "New low loss found \n",
      " Iteration: 185, Loss: 162635.86994398828\n",
      "New low loss found \n",
      " Iteration: 186, Loss: 157726.20368309\n",
      "New low loss found \n",
      " Iteration: 187, Loss: 173756.18878423158\n",
      "New low loss found \n",
      " Iteration: 188, Loss: 170415.45600528645\n",
      "New low loss found \n",
      " Iteration: 189, Loss: 178548.6123917622\n",
      "New low loss found \n",
      " Iteration: 190, Loss: 174131.10924370468\n",
      "New low loss found \n",
      " Iteration: 191, Loss: 176708.49921269566\n",
      "New low loss found \n",
      " Iteration: 192, Loss: 161327.14418186378\n",
      "New low loss found \n",
      " Iteration: 193, Loss: 157115.4292092249\n",
      "New low loss found \n",
      " Iteration: 194, Loss: 178735.12638923278\n",
      "New low loss found \n",
      " Iteration: 195, Loss: 169002.42830209812\n",
      "New low loss found \n",
      " Iteration: 196, Loss: 163940.03925158014\n",
      "New low loss found \n",
      " Iteration: 197, Loss: 171720.29096416023\n",
      "New low loss found \n",
      " Iteration: 198, Loss: 166039.38787398872\n",
      "New low loss found \n",
      " Iteration: 199, Loss: 161571.61348812282\n",
      "New low loss found \n",
      " Iteration: 200, Loss: 193577.76779880293\n",
      "New low loss found \n",
      " Iteration: 201, Loss: 187027.2169135239\n",
      "New low loss found \n",
      " Iteration: 202, Loss: 194220.9139259889\n",
      "New low loss found \n",
      " Iteration: 203, Loss: 223255.97883918142\n",
      "New low loss found \n",
      " Iteration: 204, Loss: 229567.2532813449\n",
      "New low loss found \n",
      " Iteration: 205, Loss: 214522.34787683882\n",
      "New low loss found \n",
      " Iteration: 206, Loss: 190098.38606538466\n",
      "New low loss found \n",
      " Iteration: 207, Loss: 174826.59684613012\n",
      "New low loss found \n",
      " Iteration: 208, Loss: 164131.02426041148\n",
      "New low loss found \n",
      " Iteration: 209, Loss: 161174.43329008252\n",
      "New low loss found \n",
      " Iteration: 210, Loss: 188199.501781729\n",
      "New low loss found \n",
      " Iteration: 211, Loss: 211152.84941616596\n",
      "New low loss found \n",
      " Iteration: 212, Loss: 199961.7253265076\n",
      "New low loss found \n",
      " Iteration: 213, Loss: 187730.68896264158\n",
      "New low loss found \n",
      " Iteration: 214, Loss: 163680.99688013643\n",
      "New low loss found \n",
      " Iteration: 215, Loss: 184905.2207457385\n",
      "New low loss found \n",
      " Iteration: 216, Loss: 173913.27833534824\n",
      "New low loss found \n",
      " Iteration: 217, Loss: 219360.57815285583\n",
      "New low loss found \n",
      " Iteration: 218, Loss: 242009.19765571543\n",
      "New low loss found \n",
      " Iteration: 219, Loss: 189445.93137237083\n",
      "New low loss found \n",
      " Iteration: 220, Loss: 202321.28520856897\n",
      "New low loss found \n",
      " Iteration: 221, Loss: 258694.70457798272\n",
      "New low loss found \n",
      " Iteration: 222, Loss: 249854.58923703706\n",
      "New low loss found \n",
      " Iteration: 223, Loss: 319417.188338404\n",
      "New low loss found \n",
      " Iteration: 224, Loss: 320358.30401591776\n",
      "New low loss found \n",
      " Iteration: 225, Loss: 287964.473758065\n",
      "New low loss found \n",
      " Iteration: 226, Loss: 309468.50347884034\n",
      "New low loss found \n",
      " Iteration: 227, Loss: 384290.9837840797\n",
      "New low loss found \n",
      " Iteration: 228, Loss: 343306.82024785905\n",
      "New low loss found \n",
      " Iteration: 229, Loss: 384254.5964157513\n",
      "New low loss found \n",
      " Iteration: 230, Loss: 412195.031423507\n",
      "New low loss found \n",
      " Iteration: 231, Loss: 464375.52191947977\n",
      "New low loss found \n",
      " Iteration: 232, Loss: 409542.0153157542\n",
      "New low loss found \n",
      " Iteration: 233, Loss: 345688.19298955303\n",
      "New low loss found \n",
      " Iteration: 234, Loss: 363761.4291997723\n",
      "New low loss found \n",
      " Iteration: 235, Loss: 357834.88294663886\n",
      "New low loss found \n",
      " Iteration: 236, Loss: 395921.27921751025\n",
      "New low loss found \n",
      " Iteration: 237, Loss: 305259.39697278384\n",
      "New low loss found \n",
      " Iteration: 238, Loss: 280060.26076850883\n",
      "New low loss found \n",
      " Iteration: 239, Loss: 290983.2637622096\n",
      "New low loss found \n",
      " Iteration: 240, Loss: 294400.94500021165\n",
      "New low loss found \n",
      " Iteration: 241, Loss: 412546.21001635026\n",
      "New low loss found \n",
      " Iteration: 242, Loss: 478285.5464678962\n",
      "New low loss found \n",
      " Iteration: 243, Loss: 419076.0285858095\n",
      "New low loss found \n",
      " Iteration: 244, Loss: 559153.6347466166\n",
      "New low loss found \n",
      " Iteration: 245, Loss: 549654.7428882839\n",
      "New low loss found \n",
      " Iteration: 246, Loss: 560772.8748383926\n",
      "New low loss found \n",
      " Iteration: 247, Loss: 580592.6096769978\n",
      "New low loss found \n",
      " Iteration: 248, Loss: 562404.2207728084\n",
      "New low loss found \n",
      " Iteration: 249, Loss: 560761.422640082\n",
      "New low loss found \n",
      " Iteration: 250, Loss: 550874.1138798529\n",
      "New low loss found \n",
      " Iteration: 251, Loss: 544770.2322585401\n",
      "New low loss found \n",
      " Iteration: 252, Loss: 532447.1741625492\n",
      "New low loss found \n",
      " Iteration: 253, Loss: 524234.38854594546\n",
      "New low loss found \n",
      " Iteration: 254, Loss: 578883.4861129898\n",
      "New low loss found \n",
      " Iteration: 255, Loss: 695716.8738974548\n",
      "New low loss found \n",
      " Iteration: 256, Loss: 650939.8694147225\n",
      "New low loss found \n",
      " Iteration: 257, Loss: 695658.8556645627\n",
      "New low loss found \n",
      " Iteration: 258, Loss: 583219.8408025333\n",
      "New low loss found \n",
      " Iteration: 259, Loss: 697318.6081288797\n",
      "New low loss found \n",
      " Iteration: 260, Loss: 762524.4829658858\n",
      "New low loss found \n",
      " Iteration: 262, Loss: 759439.4797550852\n",
      "New low loss found \n",
      " Iteration: 266, Loss: 732910.7038465972\n",
      "New low loss found \n",
      " Iteration: 267, Loss: 747427.6091489488\n",
      "New low loss found \n",
      " Iteration: 268, Loss: 684692.2119092385\n",
      "New low loss found \n",
      " Iteration: 269, Loss: 650666.2635197291\n",
      "New low loss found \n",
      " Iteration: 270, Loss: 679358.3831602564\n",
      "New low loss found \n",
      " Iteration: 271, Loss: 776145.8494030405\n",
      "New low loss found \n",
      " Iteration: 274, Loss: 726734.7594543095\n",
      "New low loss found \n",
      " Iteration: 275, Loss: 685248.2043328364\n",
      "New low loss found \n",
      " Iteration: 276, Loss: 686494.6480574746\n",
      "New low loss found \n",
      " Iteration: 277, Loss: 685429.4605234391\n",
      "New low loss found \n",
      " Iteration: 278, Loss: 750296.5844052498\n",
      "New low loss found \n",
      " Iteration: 280, Loss: 733510.2173667846\n",
      "New low loss found \n",
      " Iteration: 281, Loss: 668138.2752550098\n",
      "New low loss found \n",
      " Iteration: 282, Loss: 674351.4541884357\n",
      "New low loss found \n",
      " Iteration: 283, Loss: 675125.413754581\n",
      "New low loss found \n",
      " Iteration: 284, Loss: 611023.8253965316\n",
      "New low loss found \n",
      " Iteration: 285, Loss: 614841.5265010251\n",
      "New low loss found \n",
      " Iteration: 286, Loss: 595984.7440329833\n",
      "New low loss found \n",
      " Iteration: 287, Loss: 565852.5432756824\n",
      "New low loss found \n",
      " Iteration: 288, Loss: 573673.2284468944\n",
      "New low loss found \n",
      " Iteration: 289, Loss: 522240.9186264675\n",
      "New low loss found \n",
      " Iteration: 290, Loss: 556409.9947681992\n",
      "New low loss found \n",
      " Iteration: 291, Loss: 489250.7701879387\n",
      "New low loss found \n",
      " Iteration: 292, Loss: 537493.8274301843\n",
      "New low loss found \n",
      " Iteration: 293, Loss: 574546.7056691388\n",
      "New low loss found \n",
      " Iteration: 294, Loss: 549745.6887988893\n",
      "New low loss found \n",
      " Iteration: 295, Loss: 560851.6691452139\n",
      "New low loss found \n",
      " Iteration: 296, Loss: 525880.246172854\n",
      "New low loss found \n",
      " Iteration: 297, Loss: 579971.1824913672\n",
      "New low loss found \n",
      " Iteration: 298, Loss: 655883.1787164725\n",
      "New low loss found \n",
      " Iteration: 299, Loss: 683085.7613093269\n",
      "New low loss found \n",
      " Iteration: 300, Loss: 697758.2469388446\n",
      "New low loss found \n",
      " Iteration: 301, Loss: 691115.460635003\n",
      "New low loss found \n",
      " Iteration: 302, Loss: 596457.4449502822\n",
      "New low loss found \n",
      " Iteration: 303, Loss: 621992.8783154069\n",
      "New low loss found \n",
      " Iteration: 304, Loss: 626035.8468138644\n",
      "New low loss found \n",
      " Iteration: 305, Loss: 658689.717529132\n",
      "New low loss found \n",
      " Iteration: 306, Loss: 761585.9093701249\n",
      "New low loss found \n",
      " Iteration: 307, Loss: 761417.3112973836\n",
      "New low loss found \n",
      " Iteration: 308, Loss: 767776.3344555598\n",
      "New low loss found \n",
      " Iteration: 309, Loss: 734166.5686710766\n",
      "New low loss found \n",
      " Iteration: 312, Loss: 639686.5084022197\n",
      "New low loss found \n",
      " Iteration: 313, Loss: 621843.023970948\n",
      "New low loss found \n",
      " Iteration: 314, Loss: 672154.1100860902\n",
      "New low loss found \n",
      " Iteration: 315, Loss: 671080.9717653405\n",
      "New low loss found \n",
      " Iteration: 316, Loss: 654256.0146718997\n",
      "New low loss found \n",
      " Iteration: 317, Loss: 647145.1655289972\n",
      "New low loss found \n",
      " Iteration: 318, Loss: 571292.9472283031\n",
      "New low loss found \n",
      " Iteration: 319, Loss: 597732.8879059153\n",
      "New low loss found \n",
      " Iteration: 320, Loss: 580827.6740920194\n",
      "New low loss found \n",
      " Iteration: 321, Loss: 541688.2952261668\n",
      "New low loss found \n",
      " Iteration: 322, Loss: 560620.1655288675\n",
      "New low loss found \n",
      " Iteration: 323, Loss: 633518.1502305175\n",
      "New low loss found \n",
      " Iteration: 324, Loss: 641603.4020581789\n",
      "New low loss found \n",
      " Iteration: 325, Loss: 691421.0962412083\n",
      "New low loss found \n",
      " Iteration: 326, Loss: 729829.7645588303\n",
      "New low loss found \n",
      " Iteration: 327, Loss: 699732.9695270509\n",
      "New low loss found \n",
      " Iteration: 328, Loss: 716055.4395110444\n",
      "New low loss found \n",
      " Iteration: 329, Loss: 678202.8515661818\n",
      "New low loss found \n",
      " Iteration: 331, Loss: 628619.3057699953\n",
      "New low loss found \n",
      " Iteration: 332, Loss: 683120.0650084717\n",
      "New low loss found \n",
      " Iteration: 333, Loss: 660752.750268082\n",
      "New low loss found \n",
      " Iteration: 334, Loss: 628073.1675854678\n",
      "New low loss found \n",
      " Iteration: 335, Loss: 620937.3077531523\n",
      "New low loss found \n",
      " Iteration: 336, Loss: 671971.3093179695\n",
      "New low loss found \n",
      " Iteration: 337, Loss: 592314.9868679862\n",
      "New low loss found \n",
      " Iteration: 338, Loss: 588052.4650706571\n",
      "New low loss found \n",
      " Iteration: 339, Loss: 625723.1875684648\n",
      "New low loss found \n",
      " Iteration: 340, Loss: 684143.844446194\n",
      "New low loss found \n",
      " Iteration: 341, Loss: 714576.8009633952\n",
      "New low loss found \n",
      " Iteration: 342, Loss: 625220.613129686\n",
      "New low loss found \n",
      " Iteration: 343, Loss: 685438.5237478538\n",
      "New low loss found \n",
      " Iteration: 344, Loss: 727450.9593743507\n",
      "New low loss found \n",
      " Iteration: 345, Loss: 728111.8092937731\n",
      "New low loss found \n",
      " Iteration: 346, Loss: 722208.2841575263\n",
      "New low loss found \n",
      " Iteration: 347, Loss: 659736.0378360491\n",
      "New low loss found \n",
      " Iteration: 348, Loss: 632690.7547536115\n",
      "New low loss found \n",
      " Iteration: 349, Loss: 722974.5693806007\n",
      "New low loss found \n",
      " Iteration: 350, Loss: 638520.0546198813\n",
      "New low loss found \n",
      " Iteration: 351, Loss: 694429.974743064\n",
      "New low loss found \n",
      " Iteration: 352, Loss: 715294.3796243147\n",
      "New low loss found \n",
      " Iteration: 353, Loss: 655598.9128501478\n",
      "New low loss found \n",
      " Iteration: 354, Loss: 731091.5650116969\n",
      "New low loss found \n",
      " Iteration: 355, Loss: 753338.3871717846\n",
      "New low loss found \n",
      " Iteration: 356, Loss: 768371.6563941593\n",
      "New low loss found \n",
      " Iteration: 360, Loss: 717767.835913257\n",
      "New low loss found \n",
      " Iteration: 361, Loss: 722461.5794580854\n",
      "New low loss found \n",
      " Iteration: 362, Loss: 733344.0820403448\n",
      "New low loss found \n",
      " Iteration: 363, Loss: 749342.6461365189\n",
      "New low loss found \n",
      " Iteration: 364, Loss: 762374.0352684244\n",
      "New low loss found \n",
      " Iteration: 365, Loss: 778807.6544546335\n",
      "New low loss found \n",
      " Iteration: 367, Loss: 739895.541956254\n",
      "New low loss found \n",
      " Iteration: 368, Loss: 724972.8904185698\n",
      "New low loss found \n",
      " Iteration: 369, Loss: 699175.1757616346\n",
      "New low loss found \n",
      " Iteration: 370, Loss: 712744.3209139013\n",
      "New low loss found \n",
      " Iteration: 371, Loss: 714775.4569797331\n",
      "New low loss found \n",
      " Iteration: 372, Loss: 771703.7249363707\n",
      "New low loss found \n",
      " Iteration: 373, Loss: 746296.4501800914\n",
      "New low loss found \n",
      " Iteration: 374, Loss: 769216.7241773434\n",
      "New low loss found \n",
      " Iteration: 378, Loss: 702778.5725867593\n",
      "New low loss found \n",
      " Iteration: 379, Loss: 685863.0399785008\n",
      "New low loss found \n",
      " Iteration: 380, Loss: 761414.2908925973\n",
      "New low loss found \n",
      " Iteration: 381, Loss: 722501.3581410286\n",
      "New low loss found \n",
      " Iteration: 382, Loss: 715177.7793326875\n",
      "New low loss found \n",
      " Iteration: 383, Loss: 585872.0254719297\n",
      "New low loss found \n",
      " Iteration: 384, Loss: 567124.6918454804\n",
      "New low loss found \n",
      " Iteration: 385, Loss: 544438.0707685326\n",
      "New low loss found \n",
      " Iteration: 386, Loss: 439575.0518715732\n",
      "New low loss found \n",
      " Iteration: 387, Loss: 433686.8223869422\n",
      "New low loss found \n",
      " Iteration: 388, Loss: 439119.4871325529\n",
      "New low loss found \n",
      " Iteration: 389, Loss: 482999.8914716843\n",
      "New low loss found \n",
      " Iteration: 390, Loss: 493020.692299271\n",
      "New low loss found \n",
      " Iteration: 391, Loss: 492241.8762821725\n",
      "New low loss found \n",
      " Iteration: 392, Loss: 465846.48353318666\n",
      "New low loss found \n",
      " Iteration: 393, Loss: 479679.25617805077\n",
      "New low loss found \n",
      " Iteration: 394, Loss: 477940.54026021034\n",
      "New low loss found \n",
      " Iteration: 395, Loss: 470681.1202988265\n",
      "New low loss found \n",
      " Iteration: 396, Loss: 513587.63304609904\n",
      "New low loss found \n",
      " Iteration: 397, Loss: 448155.2441595175\n",
      "New low loss found \n",
      " Iteration: 398, Loss: 499412.6123071124\n",
      "New low loss found \n",
      " Iteration: 399, Loss: 538057.3795845218\n",
      "New low loss found \n",
      " Iteration: 400, Loss: 566203.9460432049\n",
      "New low loss found \n",
      " Iteration: 401, Loss: 599754.7223883772\n",
      "New low loss found \n",
      " Iteration: 402, Loss: 633149.0256924147\n",
      "New low loss found \n",
      " Iteration: 403, Loss: 641249.288813207\n",
      "New low loss found \n",
      " Iteration: 404, Loss: 606341.9656604481\n",
      "New low loss found \n",
      " Iteration: 405, Loss: 619342.198745811\n",
      "New low loss found \n",
      " Iteration: 406, Loss: 635787.3414666784\n",
      "New low loss found \n",
      " Iteration: 407, Loss: 613809.7345313902\n",
      "New low loss found \n",
      " Iteration: 408, Loss: 635045.746634803\n",
      "New low loss found \n",
      " Iteration: 409, Loss: 641578.4598180287\n",
      "New low loss found \n",
      " Iteration: 410, Loss: 660167.9322187051\n",
      "New low loss found \n",
      " Iteration: 411, Loss: 560309.0580575\n",
      "New low loss found \n",
      " Iteration: 412, Loss: 577306.0306598486\n",
      "New low loss found \n",
      " Iteration: 413, Loss: 662614.7812554945\n",
      "New low loss found \n",
      " Iteration: 414, Loss: 619308.0989059935\n",
      "New low loss found \n",
      " Iteration: 415, Loss: 577491.9081186283\n",
      "New low loss found \n",
      " Iteration: 416, Loss: 622479.2781236055\n",
      "New low loss found \n",
      " Iteration: 417, Loss: 624495.3050664536\n",
      "New low loss found \n",
      " Iteration: 418, Loss: 637581.170220767\n",
      "New low loss found \n",
      " Iteration: 419, Loss: 647321.6437774431\n",
      "New low loss found \n",
      " Iteration: 420, Loss: 758382.1749443096\n",
      "New low loss found \n",
      " Iteration: 421, Loss: 628610.6271494617\n",
      "New low loss found \n",
      " Iteration: 422, Loss: 664291.0757297064\n",
      "New low loss found \n",
      " Iteration: 423, Loss: 648231.498676055\n",
      "New low loss found \n",
      " Iteration: 424, Loss: 679432.6965476361\n",
      "New low loss found \n",
      " Iteration: 425, Loss: 679350.0815046267\n",
      "New low loss found \n",
      " Iteration: 426, Loss: 654904.9108389373\n",
      "New low loss found \n",
      " Iteration: 427, Loss: 590784.6702006051\n",
      "New low loss found \n",
      " Iteration: 428, Loss: 566688.6980170971\n",
      "New low loss found \n",
      " Iteration: 429, Loss: 566529.578027206\n",
      "New low loss found \n",
      " Iteration: 430, Loss: 564579.2394130212\n",
      "New low loss found \n",
      " Iteration: 431, Loss: 538590.3217159212\n",
      "New low loss found \n",
      " Iteration: 432, Loss: 550790.266113903\n",
      "New low loss found \n",
      " Iteration: 433, Loss: 605247.8488264969\n",
      "New low loss found \n",
      " Iteration: 434, Loss: 584178.7232695236\n",
      "New low loss found \n",
      " Iteration: 435, Loss: 617262.8247746235\n",
      "New low loss found \n",
      " Iteration: 436, Loss: 671024.6487972056\n",
      "New low loss found \n",
      " Iteration: 437, Loss: 700931.9736716397\n",
      "New low loss found \n",
      " Iteration: 438, Loss: 711235.7421988941\n",
      "New low loss found \n",
      " Iteration: 439, Loss: 726548.97470354\n",
      "New low loss found \n",
      " Iteration: 440, Loss: 681549.1164131036\n",
      "New low loss found \n",
      " Iteration: 441, Loss: 723993.1339211849\n",
      "New low loss found \n",
      " Iteration: 442, Loss: 764023.8346600527\n",
      "New low loss found \n",
      " Iteration: 445, Loss: 712588.5183359102\n",
      "New low loss found \n",
      " Iteration: 446, Loss: 733669.9471184605\n",
      "New low loss found \n",
      " Iteration: 447, Loss: 695054.6782588963\n",
      "New low loss found \n",
      " Iteration: 448, Loss: 748472.7354351401\n",
      "New low loss found \n",
      " Iteration: 449, Loss: 745757.8910529083\n",
      "New low loss found \n",
      " Iteration: 450, Loss: 718817.4382288284\n",
      "New low loss found \n",
      " Iteration: 451, Loss: 641482.98276128\n",
      "New low loss found \n",
      " Iteration: 452, Loss: 624633.2725166603\n",
      "New low loss found \n",
      " Iteration: 453, Loss: 676272.5031428188\n",
      "New low loss found \n",
      " Iteration: 454, Loss: 675718.0431642511\n",
      "New low loss found \n",
      " Iteration: 455, Loss: 704943.778291682\n",
      "New low loss found \n",
      " Iteration: 456, Loss: 716347.6250594312\n",
      "New low loss found \n",
      " Iteration: 457, Loss: 715659.6105562582\n",
      "New low loss found \n",
      " Iteration: 458, Loss: 673831.2057006205\n",
      "New low loss found \n",
      " Iteration: 459, Loss: 677414.0131737156\n",
      "New low loss found \n",
      " Iteration: 460, Loss: 762326.8266506774\n",
      "New low loss found \n",
      " Iteration: 461, Loss: 687791.6567260509\n",
      "New low loss found \n",
      " Iteration: 462, Loss: 597621.3819715509\n",
      "New low loss found \n",
      " Iteration: 463, Loss: 714100.6983040285\n",
      "New low loss found \n",
      " Iteration: 464, Loss: 766878.3757063654\n",
      "New low loss found \n",
      " Iteration: 465, Loss: 728915.7047622337\n",
      "New low loss found \n",
      " Iteration: 466, Loss: 671717.3485045711\n",
      "New low loss found \n",
      " Iteration: 467, Loss: 675597.1468060502\n",
      "New low loss found \n",
      " Iteration: 468, Loss: 706531.0564037398\n",
      "New low loss found \n",
      " Iteration: 469, Loss: 714432.5013734988\n",
      "New low loss found \n",
      " Iteration: 470, Loss: 638791.7813859654\n",
      "New low loss found \n",
      " Iteration: 471, Loss: 674700.8350272437\n",
      "New low loss found \n",
      " Iteration: 472, Loss: 685068.7950412125\n",
      "New low loss found \n",
      " Iteration: 473, Loss: 637696.8743001572\n",
      "New low loss found \n",
      " Iteration: 474, Loss: 611599.6294583078\n",
      "New low loss found \n",
      " Iteration: 475, Loss: 680041.9382518296\n",
      "New low loss found \n",
      " Iteration: 476, Loss: 748116.647755308\n",
      "New low loss found \n",
      " Iteration: 477, Loss: 767719.8774822684\n",
      "New low loss found \n",
      " Iteration: 478, Loss: 700459.6678537783\n",
      "New low loss found \n",
      " Iteration: 479, Loss: 704063.9590147566\n",
      "New low loss found \n",
      " Iteration: 480, Loss: 727461.769075211\n",
      "New low loss found \n",
      " Iteration: 481, Loss: 664063.4177680688\n",
      "New low loss found \n",
      " Iteration: 482, Loss: 621479.5446551229\n",
      "New low loss found \n",
      " Iteration: 483, Loss: 557177.2257347992\n",
      "New low loss found \n",
      " Iteration: 484, Loss: 559001.3844521032\n",
      "New low loss found \n",
      " Iteration: 485, Loss: 574260.5012031932\n",
      "New low loss found \n",
      " Iteration: 486, Loss: 556428.5327180861\n",
      "New low loss found \n",
      " Iteration: 487, Loss: 605743.4398238919\n",
      "New low loss found \n",
      " Iteration: 488, Loss: 633254.0040230724\n",
      "New low loss found \n",
      " Iteration: 489, Loss: 604813.5190656711\n",
      "New low loss found \n",
      " Iteration: 490, Loss: 629318.3965998552\n",
      "New low loss found \n",
      " Iteration: 491, Loss: 600377.4116067964\n",
      "New low loss found \n",
      " Iteration: 492, Loss: 582102.1531939558\n",
      "New low loss found \n",
      " Iteration: 493, Loss: 518564.87369939126\n",
      "New low loss found \n",
      " Iteration: 494, Loss: 500696.82011423307\n",
      "New low loss found \n",
      " Iteration: 495, Loss: 475913.7276696393\n",
      "New low loss found \n",
      " Iteration: 496, Loss: 373036.3475675717\n",
      "New low loss found \n",
      " Iteration: 497, Loss: 374214.2442699761\n",
      "New low loss found \n",
      " Iteration: 498, Loss: 337216.0743815501\n",
      "New low loss found \n",
      " Iteration: 499, Loss: 314218.6930746636\n",
      "New low loss found \n",
      " Iteration: 500, Loss: 340806.4969811753\n",
      "New low loss found \n",
      " Iteration: 501, Loss: 454973.92689759115\n",
      "New low loss found \n",
      " Iteration: 502, Loss: 485120.5049494097\n",
      "New low loss found \n",
      " Iteration: 503, Loss: 471404.3765151976\n",
      "New low loss found \n",
      " Iteration: 504, Loss: 455946.6004305752\n",
      "New low loss found \n",
      " Iteration: 505, Loss: 419417.01961263566\n",
      "New low loss found \n",
      " Iteration: 506, Loss: 412483.7443456936\n",
      "New low loss found \n",
      " Iteration: 507, Loss: 394000.7382634626\n",
      "New low loss found \n",
      " Iteration: 508, Loss: 347381.7231670817\n",
      "New low loss found \n",
      " Iteration: 509, Loss: 355437.44705691136\n",
      "New low loss found \n",
      " Iteration: 510, Loss: 339947.23374275997\n",
      "New low loss found \n",
      " Iteration: 511, Loss: 319519.591114196\n",
      "New low loss found \n",
      " Iteration: 512, Loss: 321982.6888617081\n",
      "New low loss found \n",
      " Iteration: 513, Loss: 341889.6202664605\n",
      "New low loss found \n",
      " Iteration: 514, Loss: 305001.27411247697\n",
      "New low loss found \n",
      " Iteration: 515, Loss: 308108.9654693798\n",
      "New low loss found \n",
      " Iteration: 516, Loss: 277601.3050988664\n",
      "New low loss found \n",
      " Iteration: 517, Loss: 280761.8941856333\n",
      "New low loss found \n",
      " Iteration: 518, Loss: 279430.69943420775\n",
      "New low loss found \n",
      " Iteration: 519, Loss: 279747.3019049013\n",
      "New low loss found \n",
      " Iteration: 520, Loss: 284838.1214606994\n",
      "New low loss found \n",
      " Iteration: 521, Loss: 284011.19585430075\n",
      "New low loss found \n",
      " Iteration: 522, Loss: 299294.8987385424\n",
      "New low loss found \n",
      " Iteration: 523, Loss: 295770.30964493327\n",
      "New low loss found \n",
      " Iteration: 524, Loss: 326548.25688313355\n",
      "New low loss found \n",
      " Iteration: 525, Loss: 303439.55841854104\n",
      "New low loss found \n",
      " Iteration: 526, Loss: 311137.10259606526\n",
      "New low loss found \n",
      " Iteration: 527, Loss: 297432.8531936336\n",
      "New low loss found \n",
      " Iteration: 528, Loss: 292671.11785036477\n",
      "New low loss found \n",
      " Iteration: 529, Loss: 302470.96083393774\n",
      "New low loss found \n",
      " Iteration: 530, Loss: 278185.00167857273\n",
      "New low loss found \n",
      " Iteration: 531, Loss: 286008.9030735666\n",
      "New low loss found \n",
      " Iteration: 532, Loss: 277198.3759997038\n",
      "New low loss found \n",
      " Iteration: 533, Loss: 277712.42018418363\n",
      "New low loss found \n",
      " Iteration: 534, Loss: 284119.0328928232\n",
      "New low loss found \n",
      " Iteration: 535, Loss: 287944.91161857505\n",
      "New low loss found \n",
      " Iteration: 536, Loss: 294605.0299428482\n",
      "New low loss found \n",
      " Iteration: 537, Loss: 286369.67742193415\n",
      "New low loss found \n",
      " Iteration: 538, Loss: 287768.7372312313\n",
      "New low loss found \n",
      " Iteration: 539, Loss: 280442.51010104455\n",
      "New low loss found \n",
      " Iteration: 540, Loss: 317179.67574635585\n",
      "New low loss found \n",
      " Iteration: 541, Loss: 330511.7363165138\n",
      "New low loss found \n",
      " Iteration: 542, Loss: 326267.787015927\n",
      "New low loss found \n",
      " Iteration: 543, Loss: 350428.3623289792\n",
      "New low loss found \n",
      " Iteration: 544, Loss: 349954.96786377876\n",
      "New low loss found \n",
      " Iteration: 545, Loss: 364514.356566892\n",
      "New low loss found \n",
      " Iteration: 546, Loss: 446803.7446990716\n",
      "New low loss found \n",
      " Iteration: 547, Loss: 452897.1754561641\n",
      "New low loss found \n",
      " Iteration: 548, Loss: 456528.8949067667\n",
      "New low loss found \n",
      " Iteration: 549, Loss: 489529.7943793268\n",
      "New low loss found \n",
      " Iteration: 550, Loss: 449412.5230744054\n",
      "New low loss found \n",
      " Iteration: 551, Loss: 459066.43043683824\n",
      "New low loss found \n",
      " Iteration: 552, Loss: 413176.6947215017\n",
      "New low loss found \n",
      " Iteration: 553, Loss: 380652.11258717225\n",
      "New low loss found \n",
      " Iteration: 554, Loss: 364447.45845338283\n",
      "New low loss found \n",
      " Iteration: 555, Loss: 409053.6383706461\n",
      "New low loss found \n",
      " Iteration: 556, Loss: 390417.5131783682\n",
      "New low loss found \n",
      " Iteration: 557, Loss: 402797.4173989089\n",
      "New low loss found \n",
      " Iteration: 558, Loss: 384486.69796275854\n",
      "New low loss found \n",
      " Iteration: 559, Loss: 401889.0961865099\n",
      "New low loss found \n",
      " Iteration: 560, Loss: 461538.14210867183\n",
      "New low loss found \n",
      " Iteration: 561, Loss: 507935.82757500466\n",
      "New low loss found \n",
      " Iteration: 562, Loss: 479915.14607793477\n",
      "New low loss found \n",
      " Iteration: 563, Loss: 407488.76517836435\n",
      "New low loss found \n",
      " Iteration: 564, Loss: 360761.9975331946\n",
      "New low loss found \n",
      " Iteration: 565, Loss: 377124.07679213583\n",
      "New low loss found \n",
      " Iteration: 566, Loss: 398940.71412982524\n",
      "New low loss found \n",
      " Iteration: 567, Loss: 348530.898668549\n",
      "New low loss found \n",
      " Iteration: 568, Loss: 391824.00038615067\n",
      "New low loss found \n",
      " Iteration: 569, Loss: 378013.04168937367\n",
      "New low loss found \n",
      " Iteration: 570, Loss: 357722.9733460045\n",
      "New low loss found \n",
      " Iteration: 571, Loss: 297787.5990443367\n",
      "New low loss found \n",
      " Iteration: 572, Loss: 298825.9544249331\n",
      "New low loss found \n",
      " Iteration: 573, Loss: 279818.5158620732\n",
      "New low loss found \n",
      " Iteration: 574, Loss: 261978.41887891805\n",
      "New low loss found \n",
      " Iteration: 575, Loss: 255496.079902561\n",
      "New low loss found \n",
      " Iteration: 576, Loss: 238500.12563686806\n",
      "New low loss found \n",
      " Iteration: 577, Loss: 236543.919787041\n",
      "New low loss found \n",
      " Iteration: 578, Loss: 256216.91254384458\n",
      "New low loss found \n",
      " Iteration: 579, Loss: 234321.39374406266\n",
      "New low loss found \n",
      " Iteration: 580, Loss: 230048.40940925374\n",
      "New low loss found \n",
      " Iteration: 581, Loss: 301100.6617743743\n",
      "New low loss found \n",
      " Iteration: 582, Loss: 277585.3583630229\n",
      "New low loss found \n",
      " Iteration: 583, Loss: 279649.802516794\n",
      "New low loss found \n",
      " Iteration: 584, Loss: 320277.4993561978\n",
      "New low loss found \n",
      " Iteration: 585, Loss: 344844.96161917545\n",
      "New low loss found \n",
      " Iteration: 586, Loss: 398974.1477940379\n",
      "New low loss found \n",
      " Iteration: 587, Loss: 378734.97618944565\n",
      "New low loss found \n",
      " Iteration: 588, Loss: 403047.7504177358\n",
      "New low loss found \n",
      " Iteration: 589, Loss: 346201.84804531926\n",
      "New low loss found \n",
      " Iteration: 590, Loss: 349573.31285432633\n",
      "New low loss found \n",
      " Iteration: 591, Loss: 469278.048712024\n",
      "New low loss found \n",
      " Iteration: 592, Loss: 500697.18928745156\n",
      "New low loss found \n",
      " Iteration: 593, Loss: 450864.49013398093\n",
      "New low loss found \n",
      " Iteration: 594, Loss: 434701.86372363125\n",
      "New low loss found \n",
      " Iteration: 595, Loss: 433011.0394987425\n",
      "New low loss found \n",
      " Iteration: 596, Loss: 385863.0768488205\n",
      "New low loss found \n",
      " Iteration: 597, Loss: 418327.1260169669\n",
      "New low loss found \n",
      " Iteration: 598, Loss: 406845.0514495347\n",
      "New low loss found \n",
      " Iteration: 599, Loss: 359218.10027272603\n",
      "New low loss found \n",
      " Iteration: 600, Loss: 366139.46814319264\n",
      "New low loss found \n",
      " Iteration: 601, Loss: 312416.71649926144\n",
      "New low loss found \n",
      " Iteration: 602, Loss: 331479.90215713886\n",
      "New low loss found \n",
      " Iteration: 603, Loss: 314512.17595515505\n",
      "New low loss found \n",
      " Iteration: 604, Loss: 301410.0212033558\n",
      "New low loss found \n",
      " Iteration: 605, Loss: 238306.1200150625\n",
      "New low loss found \n",
      " Iteration: 606, Loss: 232335.72030394946\n",
      "New low loss found \n",
      " Iteration: 607, Loss: 236674.33094672606\n",
      "New low loss found \n",
      " Iteration: 608, Loss: 203645.85285676646\n",
      "New low loss found \n",
      " Iteration: 609, Loss: 199570.79019516558\n",
      "New low loss found \n",
      " Iteration: 610, Loss: 206909.10364279983\n",
      "New low loss found \n",
      " Iteration: 611, Loss: 205312.48366045835\n",
      "New low loss found \n",
      " Iteration: 612, Loss: 211662.67677084816\n",
      "New low loss found \n",
      " Iteration: 613, Loss: 202722.74623643744\n",
      "New low loss found \n",
      " Iteration: 614, Loss: 211745.04119336247\n",
      "New low loss found \n",
      " Iteration: 615, Loss: 214113.67959974817\n",
      "New low loss found \n",
      " Iteration: 616, Loss: 211202.38253761648\n",
      "New low loss found \n",
      " Iteration: 617, Loss: 245507.4832731318\n",
      "New low loss found \n",
      " Iteration: 618, Loss: 274879.1478089618\n",
      "New low loss found \n",
      " Iteration: 619, Loss: 272599.2999584121\n",
      "New low loss found \n",
      " Iteration: 620, Loss: 256919.49086243677\n",
      "New low loss found \n",
      " Iteration: 621, Loss: 285475.1511807408\n",
      "New low loss found \n",
      " Iteration: 622, Loss: 284861.2001405632\n",
      "New low loss found \n",
      " Iteration: 623, Loss: 264874.2005658744\n",
      "New low loss found \n",
      " Iteration: 624, Loss: 252945.6698809871\n",
      "New low loss found \n",
      " Iteration: 625, Loss: 262381.12172739144\n",
      "New low loss found \n",
      " Iteration: 626, Loss: 273410.25832579494\n",
      "New low loss found \n",
      " Iteration: 627, Loss: 266171.3402003534\n",
      "New low loss found \n",
      " Iteration: 628, Loss: 265965.42368203134\n",
      "New low loss found \n",
      " Iteration: 629, Loss: 243907.29153566237\n",
      "New low loss found \n",
      " Iteration: 630, Loss: 284557.6271344436\n",
      "New low loss found \n",
      " Iteration: 631, Loss: 257225.45654037414\n",
      "New low loss found \n",
      " Iteration: 632, Loss: 256331.3205672569\n",
      "New low loss found \n",
      " Iteration: 633, Loss: 239845.5927582233\n",
      "New low loss found \n",
      " Iteration: 634, Loss: 256959.51556333946\n",
      "New low loss found \n",
      " Iteration: 635, Loss: 297887.9205400299\n",
      "New low loss found \n",
      " Iteration: 636, Loss: 290078.1119857816\n",
      "New low loss found \n",
      " Iteration: 637, Loss: 311544.7525132255\n",
      "New low loss found \n",
      " Iteration: 638, Loss: 301770.6699047675\n",
      "New low loss found \n",
      " Iteration: 639, Loss: 291559.98424032354\n",
      "New low loss found \n",
      " Iteration: 640, Loss: 357272.2267726204\n",
      "New low loss found \n",
      " Iteration: 641, Loss: 335017.6009111061\n",
      "New low loss found \n",
      " Iteration: 642, Loss: 373537.66096216184\n",
      "New low loss found \n",
      " Iteration: 643, Loss: 390212.44465250085\n",
      "New low loss found \n",
      " Iteration: 644, Loss: 394832.673043\n",
      "New low loss found \n",
      " Iteration: 645, Loss: 370008.7628833769\n",
      "New low loss found \n",
      " Iteration: 646, Loss: 300240.20989632455\n",
      "New low loss found \n",
      " Iteration: 647, Loss: 392530.87089318567\n",
      "New low loss found \n",
      " Iteration: 648, Loss: 346685.0841714223\n",
      "New low loss found \n",
      " Iteration: 649, Loss: 302989.0312436537\n",
      "New low loss found \n",
      " Iteration: 650, Loss: 297177.86173053854\n",
      "New low loss found \n",
      " Iteration: 651, Loss: 318331.8316937647\n",
      "New low loss found \n",
      " Iteration: 652, Loss: 273904.6740327511\n",
      "New low loss found \n",
      " Iteration: 653, Loss: 243845.84671782423\n",
      "New low loss found \n",
      " Iteration: 654, Loss: 241378.6264002192\n",
      "New low loss found \n",
      " Iteration: 655, Loss: 242419.57412935616\n",
      "New low loss found \n",
      " Iteration: 656, Loss: 238034.78600323477\n",
      "New low loss found \n",
      " Iteration: 657, Loss: 252867.40296575578\n",
      "New low loss found \n",
      " Iteration: 658, Loss: 259186.07296762246\n",
      "New low loss found \n",
      " Iteration: 659, Loss: 264467.91592667165\n",
      "New low loss found \n",
      " Iteration: 660, Loss: 295343.1812038653\n",
      "New low loss found \n",
      " Iteration: 661, Loss: 298622.47791083204\n",
      "New low loss found \n",
      " Iteration: 662, Loss: 315128.45650719554\n",
      "New low loss found \n",
      " Iteration: 663, Loss: 370952.17081145744\n",
      "New low loss found \n",
      " Iteration: 664, Loss: 308190.57493958843\n",
      "New low loss found \n",
      " Iteration: 665, Loss: 336772.21101462597\n",
      "New low loss found \n",
      " Iteration: 666, Loss: 305060.2130981992\n",
      "New low loss found \n",
      " Iteration: 667, Loss: 305070.88408980035\n",
      "New low loss found \n",
      " Iteration: 668, Loss: 333114.05193979054\n",
      "New low loss found \n",
      " Iteration: 669, Loss: 326292.95449480513\n",
      "New low loss found \n",
      " Iteration: 670, Loss: 334866.1886882565\n",
      "New low loss found \n",
      " Iteration: 671, Loss: 328328.0014919922\n",
      "New low loss found \n",
      " Iteration: 672, Loss: 317457.0495453552\n",
      "New low loss found \n",
      " Iteration: 673, Loss: 273957.7071852064\n",
      "New low loss found \n",
      " Iteration: 674, Loss: 256196.31603294885\n",
      "New low loss found \n",
      " Iteration: 675, Loss: 269958.72633327724\n",
      "New low loss found \n",
      " Iteration: 676, Loss: 275456.9818279446\n",
      "New low loss found \n",
      " Iteration: 677, Loss: 272639.9814559152\n",
      "New low loss found \n",
      " Iteration: 678, Loss: 275548.23201740714\n",
      "New low loss found \n",
      " Iteration: 679, Loss: 279175.4505950064\n",
      "New low loss found \n",
      " Iteration: 680, Loss: 276859.9271470163\n",
      "New low loss found \n",
      " Iteration: 681, Loss: 270062.5331228112\n",
      "New low loss found \n",
      " Iteration: 682, Loss: 298273.2584097416\n",
      "New low loss found \n",
      " Iteration: 683, Loss: 314324.54419490934\n",
      "New low loss found \n",
      " Iteration: 684, Loss: 357674.36123713345\n",
      "New low loss found \n",
      " Iteration: 685, Loss: 338887.121344762\n",
      "New low loss found \n",
      " Iteration: 686, Loss: 362148.0497398363\n",
      "New low loss found \n",
      " Iteration: 687, Loss: 380725.65489186475\n",
      "New low loss found \n",
      " Iteration: 688, Loss: 338746.57730418636\n",
      "New low loss found \n",
      " Iteration: 689, Loss: 318475.416564432\n",
      "New low loss found \n",
      " Iteration: 690, Loss: 346455.0389407234\n",
      "New low loss found \n",
      " Iteration: 691, Loss: 332066.25288963184\n",
      "New low loss found \n",
      " Iteration: 692, Loss: 318164.0695544292\n",
      "New low loss found \n",
      " Iteration: 693, Loss: 306052.1227034085\n",
      "New low loss found \n",
      " Iteration: 694, Loss: 294633.84267992503\n",
      "New low loss found \n",
      " Iteration: 695, Loss: 278342.1373787391\n",
      "New low loss found \n",
      " Iteration: 696, Loss: 288781.64455605944\n",
      "New low loss found \n",
      " Iteration: 697, Loss: 271602.33710299834\n",
      "New low loss found \n",
      " Iteration: 698, Loss: 271830.4459818693\n",
      "New low loss found \n",
      " Iteration: 699, Loss: 271082.6917868794\n",
      "New low loss found \n",
      " Iteration: 700, Loss: 249081.2911542966\n",
      "New low loss found \n",
      " Iteration: 701, Loss: 244113.548644545\n",
      "New low loss found \n",
      " Iteration: 702, Loss: 223455.49364285488\n",
      "New low loss found \n",
      " Iteration: 703, Loss: 233148.08935146697\n",
      "New low loss found \n",
      " Iteration: 704, Loss: 234265.43942228812\n",
      "New low loss found \n",
      " Iteration: 705, Loss: 243403.6517111865\n",
      "New low loss found \n",
      " Iteration: 706, Loss: 250509.62174831444\n",
      "New low loss found \n",
      " Iteration: 707, Loss: 243069.7057864713\n",
      "New low loss found \n",
      " Iteration: 708, Loss: 238019.21124974516\n",
      "New low loss found \n",
      " Iteration: 709, Loss: 246798.9989658567\n",
      "New low loss found \n",
      " Iteration: 710, Loss: 265448.89598655025\n",
      "New low loss found \n",
      " Iteration: 711, Loss: 268149.7263484968\n",
      "New low loss found \n",
      " Iteration: 712, Loss: 294285.06926525885\n",
      "New low loss found \n",
      " Iteration: 713, Loss: 283998.1816798285\n",
      "New low loss found \n",
      " Iteration: 714, Loss: 274530.6851574529\n",
      "New low loss found \n",
      " Iteration: 715, Loss: 289722.4035318254\n",
      "New low loss found \n",
      " Iteration: 716, Loss: 273247.2075268794\n",
      "New low loss found \n",
      " Iteration: 717, Loss: 278943.78488726827\n",
      "New low loss found \n",
      " Iteration: 718, Loss: 274098.65142670454\n",
      "New low loss found \n",
      " Iteration: 719, Loss: 287494.67565555\n",
      "New low loss found \n",
      " Iteration: 720, Loss: 289983.88909639616\n",
      "New low loss found \n",
      " Iteration: 721, Loss: 290797.8703384001\n",
      "New low loss found \n",
      " Iteration: 722, Loss: 301261.86033688264\n",
      "New low loss found \n",
      " Iteration: 723, Loss: 298146.7658607652\n",
      "New low loss found \n",
      " Iteration: 724, Loss: 304131.5223486948\n",
      "New low loss found \n",
      " Iteration: 725, Loss: 307625.64911309717\n",
      "New low loss found \n",
      " Iteration: 726, Loss: 309970.78363900987\n",
      "New low loss found \n",
      " Iteration: 727, Loss: 314475.85132657527\n",
      "New low loss found \n",
      " Iteration: 728, Loss: 307636.69891067373\n",
      "New low loss found \n",
      " Iteration: 729, Loss: 303768.93852505874\n",
      "New low loss found \n",
      " Iteration: 730, Loss: 301263.4801916893\n",
      "New low loss found \n",
      " Iteration: 731, Loss: 312392.8571542831\n",
      "New low loss found \n",
      " Iteration: 732, Loss: 310125.1795421514\n",
      "New low loss found \n",
      " Iteration: 733, Loss: 297061.4421651388\n",
      "New low loss found \n",
      " Iteration: 734, Loss: 324746.6650524577\n",
      "New low loss found \n",
      " Iteration: 735, Loss: 343966.84000437823\n",
      "New low loss found \n",
      " Iteration: 736, Loss: 353830.0528743655\n",
      "New low loss found \n",
      " Iteration: 737, Loss: 354676.4045954102\n",
      "New low loss found \n",
      " Iteration: 738, Loss: 351846.6767232696\n",
      "New low loss found \n",
      " Iteration: 739, Loss: 411011.96469505655\n",
      "New low loss found \n",
      " Iteration: 740, Loss: 397795.6659290951\n",
      "New low loss found \n",
      " Iteration: 741, Loss: 423032.95177848067\n",
      "New low loss found \n",
      " Iteration: 742, Loss: 434287.49928853795\n",
      "New low loss found \n",
      " Iteration: 743, Loss: 431145.62356564536\n",
      "New low loss found \n",
      " Iteration: 744, Loss: 359567.1694776445\n",
      "New low loss found \n",
      " Iteration: 745, Loss: 340759.60331197054\n",
      "New low loss found \n",
      " Iteration: 746, Loss: 357948.64565734507\n",
      "New low loss found \n",
      " Iteration: 747, Loss: 367036.2265711858\n",
      "New low loss found \n",
      " Iteration: 748, Loss: 356302.49808909337\n",
      "New low loss found \n",
      " Iteration: 749, Loss: 330566.25168371765\n",
      "New low loss found \n",
      " Iteration: 750, Loss: 338270.27467471774\n",
      "New low loss found \n",
      " Iteration: 751, Loss: 354462.26907960523\n",
      "New low loss found \n",
      " Iteration: 752, Loss: 386070.70544513006\n",
      "New low loss found \n",
      " Iteration: 753, Loss: 377915.88296392426\n",
      "New low loss found \n",
      " Iteration: 754, Loss: 352361.89353952324\n",
      "New low loss found \n",
      " Iteration: 755, Loss: 341620.1240291697\n",
      "New low loss found \n",
      " Iteration: 756, Loss: 329585.33848351875\n",
      "New low loss found \n",
      " Iteration: 757, Loss: 320159.6040994142\n",
      "New low loss found \n",
      " Iteration: 758, Loss: 307844.94474945223\n",
      "New low loss found \n",
      " Iteration: 759, Loss: 321017.93036930705\n",
      "New low loss found \n",
      " Iteration: 760, Loss: 331933.6655098632\n",
      "New low loss found \n",
      " Iteration: 761, Loss: 326923.6995563038\n",
      "New low loss found \n",
      " Iteration: 762, Loss: 312657.7317370138\n",
      "New low loss found \n",
      " Iteration: 763, Loss: 328083.9554219279\n",
      "New low loss found \n",
      " Iteration: 764, Loss: 378927.57817426766\n",
      "New low loss found \n",
      " Iteration: 765, Loss: 310881.440912958\n",
      "New low loss found \n",
      " Iteration: 766, Loss: 311177.11452468776\n",
      "New low loss found \n",
      " Iteration: 767, Loss: 307277.83117841603\n",
      "New low loss found \n",
      " Iteration: 768, Loss: 328173.7403819865\n",
      "New low loss found \n",
      " Iteration: 769, Loss: 381660.2535252808\n",
      "New low loss found \n",
      " Iteration: 770, Loss: 329433.0720142687\n",
      "New low loss found \n",
      " Iteration: 771, Loss: 357933.46973235917\n",
      "New low loss found \n",
      " Iteration: 772, Loss: 388832.3174425321\n",
      "New low loss found \n",
      " Iteration: 773, Loss: 356153.3847495044\n",
      "New low loss found \n",
      " Iteration: 774, Loss: 378698.2788275748\n",
      "New low loss found \n",
      " Iteration: 775, Loss: 435397.68554976134\n",
      "New low loss found \n",
      " Iteration: 776, Loss: 519434.3615281038\n",
      "New low loss found \n",
      " Iteration: 777, Loss: 499969.97435658774\n",
      "New low loss found \n",
      " Iteration: 778, Loss: 508544.6868396711\n",
      "New low loss found \n",
      " Iteration: 779, Loss: 554723.5697986927\n",
      "New low loss found \n",
      " Iteration: 780, Loss: 641939.506504216\n",
      "New low loss found \n",
      " Iteration: 781, Loss: 590389.6423329046\n",
      "New low loss found \n",
      " Iteration: 782, Loss: 611793.317902797\n",
      "New low loss found \n",
      " Iteration: 783, Loss: 594556.0436871875\n",
      "New low loss found \n",
      " Iteration: 784, Loss: 619596.7676922047\n",
      "New low loss found \n",
      " Iteration: 785, Loss: 643387.142158212\n",
      "New low loss found \n",
      " Iteration: 786, Loss: 654986.7124340347\n",
      "New low loss found \n",
      " Iteration: 787, Loss: 696840.3908286873\n",
      "New low loss found \n",
      " Iteration: 788, Loss: 664881.0480270195\n",
      "New low loss found \n",
      " Iteration: 789, Loss: 650512.2831665243\n",
      "New low loss found \n",
      " Iteration: 790, Loss: 617283.1593693902\n",
      "New low loss found \n",
      " Iteration: 791, Loss: 621312.2595082992\n",
      "New low loss found \n",
      " Iteration: 792, Loss: 710448.6879765211\n",
      "New low loss found \n",
      " Iteration: 793, Loss: 697842.2785914077\n",
      "New low loss found \n",
      " Iteration: 794, Loss: 737594.9436202311\n",
      "New low loss found \n",
      " Iteration: 796, Loss: 767996.5601213104\n",
      "New low loss found \n",
      " Iteration: 798, Loss: 758598.3468146694\n",
      "New low loss found \n",
      " Iteration: 799, Loss: 717707.5848392682\n",
      "New low loss found \n",
      " Iteration: 801, Loss: 704495.0368747656\n",
      "New low loss found \n",
      " Iteration: 802, Loss: 715152.6274311838\n",
      "New low loss found \n",
      " Iteration: 803, Loss: 686865.7901044777\n",
      "New low loss found \n",
      " Iteration: 804, Loss: 711358.0562270995\n",
      "New low loss found \n",
      " Iteration: 805, Loss: 681689.9030039099\n",
      "New low loss found \n",
      " Iteration: 806, Loss: 718443.6007081344\n",
      "New low loss found \n",
      " Iteration: 807, Loss: 675557.895637149\n",
      "New low loss found \n",
      " Iteration: 808, Loss: 715139.1163502677\n",
      "New low loss found \n",
      " Iteration: 809, Loss: 686845.7914185709\n",
      "New low loss found \n",
      " Iteration: 810, Loss: 662854.2107604158\n",
      "New low loss found \n",
      " Iteration: 811, Loss: 751334.4654024192\n",
      "New low loss found \n",
      " Iteration: 812, Loss: 766641.7351021564\n",
      "New low loss found \n",
      " Iteration: 813, Loss: 632635.822978641\n",
      "New low loss found \n",
      " Iteration: 814, Loss: 684275.5770046917\n",
      "New low loss found \n",
      " Iteration: 815, Loss: 629988.8390800392\n",
      "New low loss found \n",
      " Iteration: 816, Loss: 670403.1184681826\n",
      "New low loss found \n",
      " Iteration: 817, Loss: 707392.5506478093\n",
      "New low loss found \n",
      " Iteration: 818, Loss: 755073.9131281646\n",
      "New low loss found \n",
      " Iteration: 819, Loss: 726814.8212649217\n",
      "New low loss found \n",
      " Iteration: 822, Loss: 740961.1449484266\n",
      "New low loss found \n",
      " Iteration: 823, Loss: 748200.3801543155\n",
      "New low loss found \n",
      " Iteration: 825, Loss: 694851.0796159491\n",
      "New low loss found \n",
      " Iteration: 826, Loss: 680321.558000415\n",
      "New low loss found \n",
      " Iteration: 827, Loss: 736503.2763084723\n",
      "New low loss found \n",
      " Iteration: 828, Loss: 717468.8400997341\n",
      "New low loss found \n",
      " Iteration: 829, Loss: 741120.7259301038\n",
      "New low loss found \n",
      " Iteration: 830, Loss: 714661.9820822646\n",
      "New low loss found \n",
      " Iteration: 832, Loss: 771213.3040343953\n",
      "New low loss found \n",
      " Iteration: 837, Loss: 701956.9256041258\n",
      "New low loss found \n",
      " Iteration: 838, Loss: 747722.2052821664\n",
      "New low loss found \n",
      " Iteration: 839, Loss: 736932.2885235304\n",
      "New low loss found \n",
      " Iteration: 840, Loss: 747238.541817482\n",
      "New low loss found \n",
      " Iteration: 841, Loss: 773647.1535376884\n",
      "New low loss found \n",
      " Iteration: 842, Loss: 717047.7393632272\n",
      "New low loss found \n",
      " Iteration: 843, Loss: 772452.9097244334\n",
      "New low loss found \n",
      " Iteration: 845, Loss: 735444.9929764149\n",
      "New low loss found \n",
      " Iteration: 846, Loss: 672031.0776359517\n",
      "New low loss found \n",
      " Iteration: 847, Loss: 570030.9887609774\n",
      "New low loss found \n",
      " Iteration: 848, Loss: 550961.3112435956\n",
      "New low loss found \n",
      " Iteration: 849, Loss: 556136.3449961839\n",
      "New low loss found \n",
      " Iteration: 850, Loss: 539082.6963797875\n",
      "New low loss found \n",
      " Iteration: 851, Loss: 565372.9468575256\n",
      "New low loss found \n",
      " Iteration: 852, Loss: 640335.8241763435\n",
      "New low loss found \n",
      " Iteration: 853, Loss: 672092.8865685519\n",
      "New low loss found \n",
      " Iteration: 854, Loss: 686144.5958508918\n",
      "New low loss found \n",
      " Iteration: 855, Loss: 706468.1821411267\n",
      "New low loss found \n",
      " Iteration: 856, Loss: 701070.9741247224\n",
      "New low loss found \n",
      " Iteration: 858, Loss: 607745.5815228202\n",
      "New low loss found \n",
      " Iteration: 859, Loss: 596375.0506737297\n",
      "New low loss found \n",
      " Iteration: 860, Loss: 550174.0051525759\n",
      "New low loss found \n",
      " Iteration: 861, Loss: 541297.1423036573\n",
      "New low loss found \n",
      " Iteration: 862, Loss: 495715.0792658986\n",
      "New low loss found \n",
      " Iteration: 863, Loss: 497887.1476296172\n",
      "New low loss found \n",
      " Iteration: 864, Loss: 489674.2061447197\n",
      "New low loss found \n",
      " Iteration: 865, Loss: 596228.2755944638\n",
      "New low loss found \n",
      " Iteration: 866, Loss: 644747.131846103\n",
      "New low loss found \n",
      " Iteration: 867, Loss: 624690.5402476399\n",
      "New low loss found \n",
      " Iteration: 868, Loss: 633200.1255149887\n",
      "New low loss found \n",
      " Iteration: 869, Loss: 672138.2592247677\n",
      "New low loss found \n",
      " Iteration: 870, Loss: 688785.4099898716\n",
      "New low loss found \n",
      " Iteration: 871, Loss: 730218.3439596695\n",
      "New low loss found \n",
      " Iteration: 872, Loss: 744140.0134614358\n",
      "New low loss found \n",
      " Iteration: 873, Loss: 703266.5754526263\n",
      "New low loss found \n",
      " Iteration: 874, Loss: 681277.6265267784\n",
      "New low loss found \n",
      " Iteration: 875, Loss: 749295.8941153632\n",
      "New low loss found \n",
      " Iteration: 877, Loss: 719396.2308951946\n",
      "New low loss found \n",
      " Iteration: 878, Loss: 679370.2761681585\n",
      "New low loss found \n",
      " Iteration: 879, Loss: 737277.2651887353\n",
      "New low loss found \n",
      " Iteration: 880, Loss: 769090.4051364413\n",
      "New low loss found \n",
      " Iteration: 881, Loss: 715165.2419547203\n",
      "New low loss found \n",
      " Iteration: 882, Loss: 748223.5159457226\n",
      "New low loss found \n",
      " Iteration: 883, Loss: 758563.5807749138\n",
      "New low loss found \n",
      " Iteration: 886, Loss: 722135.1732706284\n",
      "New low loss found \n",
      " Iteration: 887, Loss: 665214.4290726995\n",
      "New low loss found \n",
      " Iteration: 888, Loss: 633248.2099673746\n",
      "New low loss found \n",
      " Iteration: 889, Loss: 681380.7822375639\n",
      "New low loss found \n",
      " Iteration: 890, Loss: 662775.6842270509\n",
      "New low loss found \n",
      " Iteration: 891, Loss: 644366.8928037897\n",
      "New low loss found \n",
      " Iteration: 892, Loss: 595888.8966415178\n",
      "New low loss found \n",
      " Iteration: 893, Loss: 531759.7481646007\n",
      "New low loss found \n",
      " Iteration: 894, Loss: 550887.7678962765\n",
      "New low loss found \n",
      " Iteration: 895, Loss: 526900.8986931335\n",
      "New low loss found \n",
      " Iteration: 896, Loss: 559414.0703412031\n",
      "New low loss found \n",
      " Iteration: 897, Loss: 579448.5991126569\n",
      "New low loss found \n",
      " Iteration: 898, Loss: 542501.6783813251\n",
      "New low loss found \n",
      " Iteration: 899, Loss: 605893.1840507784\n",
      "New low loss found \n",
      " Iteration: 900, Loss: 630191.9389623429\n",
      "New low loss found \n",
      " Iteration: 901, Loss: 630551.3569183359\n",
      "New low loss found \n",
      " Iteration: 902, Loss: 576342.8973375658\n",
      "New low loss found \n",
      " Iteration: 903, Loss: 603243.7134391227\n",
      "New low loss found \n",
      " Iteration: 904, Loss: 603700.8769471106\n",
      "New low loss found \n",
      " Iteration: 905, Loss: 577206.5486558912\n",
      "New low loss found \n",
      " Iteration: 906, Loss: 630611.7018609947\n",
      "New low loss found \n",
      " Iteration: 907, Loss: 637733.7387503027\n",
      "New low loss found \n",
      " Iteration: 908, Loss: 714805.4112962242\n",
      "New low loss found \n",
      " Iteration: 909, Loss: 700663.7944439598\n",
      "New low loss found \n",
      " Iteration: 910, Loss: 660563.7053860466\n",
      "New low loss found \n",
      " Iteration: 911, Loss: 659059.8277443217\n",
      "New low loss found \n",
      " Iteration: 912, Loss: 715422.48302044\n",
      "New low loss found \n",
      " Iteration: 913, Loss: 707405.0917286765\n",
      "New low loss found \n",
      " Iteration: 914, Loss: 733413.492806591\n",
      "New low loss found \n",
      " Iteration: 915, Loss: 732621.4989093458\n",
      "New low loss found \n",
      " Iteration: 916, Loss: 759010.8301005228\n",
      "New low loss found \n",
      " Iteration: 917, Loss: 767204.9490446426\n",
      "New low loss found \n",
      " Iteration: 918, Loss: 760822.6771944187\n",
      "New low loss found \n",
      " Iteration: 919, Loss: 702493.2203738894\n",
      "New low loss found \n",
      " Iteration: 920, Loss: 664130.353625462\n",
      "New low loss found \n",
      " Iteration: 921, Loss: 738221.8356528844\n",
      "New low loss found \n",
      " Iteration: 922, Loss: 690277.4058313717\n",
      "New low loss found \n",
      " Iteration: 923, Loss: 730353.3753861467\n",
      "New low loss found \n",
      " Iteration: 924, Loss: 690755.4140953908\n",
      "New low loss found \n",
      " Iteration: 925, Loss: 662857.5071492202\n",
      "New low loss found \n",
      " Iteration: 926, Loss: 652468.2290956274\n",
      "New low loss found \n",
      " Iteration: 927, Loss: 627080.2291385054\n",
      "New low loss found \n",
      " Iteration: 928, Loss: 612100.9716346572\n",
      "New low loss found \n",
      " Iteration: 929, Loss: 582253.2360211245\n",
      "New low loss found \n",
      " Iteration: 930, Loss: 623912.6011873948\n",
      "New low loss found \n",
      " Iteration: 931, Loss: 606640.3689394059\n",
      "New low loss found \n",
      " Iteration: 932, Loss: 613424.4902215459\n",
      "New low loss found \n",
      " Iteration: 933, Loss: 624884.9763464449\n",
      "New low loss found \n",
      " Iteration: 934, Loss: 620473.5827362663\n",
      "New low loss found \n",
      " Iteration: 935, Loss: 608412.6345928068\n",
      "New low loss found \n",
      " Iteration: 936, Loss: 666004.8204019244\n",
      "New low loss found \n",
      " Iteration: 937, Loss: 644527.0281141037\n",
      "New low loss found \n",
      " Iteration: 938, Loss: 623113.6270678361\n",
      "New low loss found \n",
      " Iteration: 939, Loss: 657598.303372511\n",
      "New low loss found \n",
      " Iteration: 940, Loss: 692735.1574213068\n",
      "New low loss found \n",
      " Iteration: 941, Loss: 614444.5409750671\n",
      "New low loss found \n",
      " Iteration: 942, Loss: 601529.3691126507\n",
      "New low loss found \n",
      " Iteration: 943, Loss: 637231.0164054584\n",
      "New low loss found \n",
      " Iteration: 944, Loss: 628168.8266504947\n",
      "New low loss found \n",
      " Iteration: 945, Loss: 622561.0990518719\n",
      "New low loss found \n",
      " Iteration: 946, Loss: 701971.6180109049\n",
      "New low loss found \n",
      " Iteration: 947, Loss: 706738.1271237676\n",
      "New low loss found \n",
      " Iteration: 948, Loss: 752933.5982953612\n",
      "New low loss found \n",
      " Iteration: 949, Loss: 710352.5133302432\n",
      "New low loss found \n",
      " Iteration: 950, Loss: 681526.9583437548\n",
      "New low loss found \n",
      " Iteration: 951, Loss: 754750.2101236946\n",
      "New low loss found \n",
      " Iteration: 952, Loss: 709890.5721990325\n",
      "New low loss found \n",
      " Iteration: 953, Loss: 681408.4305818037\n",
      "New low loss found \n",
      " Iteration: 954, Loss: 616897.0044192134\n",
      "New low loss found \n",
      " Iteration: 955, Loss: 736395.3509012873\n",
      "New low loss found \n",
      " Iteration: 956, Loss: 734101.8630185849\n",
      "New low loss found \n",
      " Iteration: 957, Loss: 699301.9992408545\n",
      "New low loss found \n",
      " Iteration: 958, Loss: 652015.3257022669\n",
      "New low loss found \n",
      " Iteration: 959, Loss: 625582.6675274889\n",
      "New low loss found \n",
      " Iteration: 960, Loss: 587974.055992815\n",
      "New low loss found \n",
      " Iteration: 961, Loss: 647536.6543917271\n",
      "New low loss found \n",
      " Iteration: 962, Loss: 592060.2780453316\n",
      "New low loss found \n",
      " Iteration: 963, Loss: 599692.3499840685\n",
      "New low loss found \n",
      " Iteration: 964, Loss: 541107.5306772911\n",
      "New low loss found \n",
      " Iteration: 965, Loss: 515001.61698937597\n",
      "New low loss found \n",
      " Iteration: 966, Loss: 487170.24172081245\n",
      "New low loss found \n",
      " Iteration: 967, Loss: 456768.7588385809\n",
      "New low loss found \n",
      " Iteration: 968, Loss: 457530.4458592766\n",
      "New low loss found \n",
      " Iteration: 969, Loss: 468864.6822994311\n",
      "New low loss found \n",
      " Iteration: 970, Loss: 492036.47165071714\n",
      "New low loss found \n",
      " Iteration: 971, Loss: 512353.1323368632\n",
      "New low loss found \n",
      " Iteration: 972, Loss: 577459.3841220875\n",
      "New low loss found \n",
      " Iteration: 973, Loss: 636192.8305017753\n",
      "New low loss found \n",
      " Iteration: 974, Loss: 608356.2891155633\n",
      "New low loss found \n",
      " Iteration: 975, Loss: 674136.482907816\n",
      "New low loss found \n",
      " Iteration: 976, Loss: 701908.2962740491\n",
      "New low loss found \n",
      " Iteration: 977, Loss: 765116.5613424428\n",
      "New low loss found \n",
      " Iteration: 979, Loss: 716866.1085451792\n",
      "New low loss found \n",
      " Iteration: 980, Loss: 758923.2880242643\n",
      "New low loss found \n",
      " Iteration: 981, Loss: 770337.9893073739\n",
      "New low loss found \n",
      " Iteration: 984, Loss: 748243.1462776231\n",
      "New low loss found \n",
      " Iteration: 987, Loss: 626890.8711540558\n",
      "New low loss found \n",
      " Iteration: 988, Loss: 623850.951183384\n",
      "New low loss found \n",
      " Iteration: 989, Loss: 694910.5096724394\n",
      "New low loss found \n",
      " Iteration: 990, Loss: 686069.352452087\n",
      "New low loss found \n",
      " Iteration: 991, Loss: 709186.819318196\n",
      "New low loss found \n",
      " Iteration: 992, Loss: 711082.0276052863\n",
      "New low loss found \n",
      " Iteration: 993, Loss: 776416.928816063\n",
      "New low loss found \n",
      " Iteration: 994, Loss: 742425.2263292809\n",
      "New low loss found \n",
      " Iteration: 995, Loss: 642184.9210398622\n",
      "New low loss found \n",
      " Iteration: 996, Loss: 687253.7568196375\n",
      "New low loss found \n",
      " Iteration: 997, Loss: 661943.1243692521\n",
      "New low loss found \n",
      " Iteration: 998, Loss: 674112.796109163\n",
      "New low loss found \n",
      " Iteration: 999, Loss: 708615.4597675522\n"
     ]
    }
   ],
   "source": [
    "cur_loss = get_loss(W1,b1,W2,b2)\n",
    "losses = dict({'Loss':[],'Iteration':[]})\n",
    "for i in range(1000):\n",
    "    n_W1 = W1 + 0.05*np.random.randn(10,10)\n",
    "    n_b1 = b1 + 0.05*np.random.randn()\n",
    "    n_W2 = W2 + 0.05*np.random.randn(10,1)\n",
    "    n_b2 = b2 + 0.05*np.random.randn()\n",
    "\n",
    "    new_loss = get_loss(n_W1, n_b1, n_W2, n_b2)\n",
    "\n",
    "    if new_loss<cur_loss:\n",
    "        W1 = n_W1\n",
    "        W2 = n_W2\n",
    "        b1 = n_b1\n",
    "        b2 = n_b2\n",
    "        print(f'New low loss found \\n Iteration: {i}, Loss: {new_loss}')\n",
    "        cur_loss = new_loss\n",
    "        losses['Loss'].append(cur_loss)\n",
    "        losses['Iteration'].append(i)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_layer:\n",
    "\n",
    "    def __init__(self, input):\n",
    "        self.input = input\n",
    "        self.weights = np.random.randn(1,input.shape[1])\n",
    "        self.bias = np.random.randn()\n",
    "\n",
    "    def forward_propagation(self, input):\n",
    "        return np.dot(self.weights, input.T) + self.bias\n",
    "\n",
    "    def backward_propagation(self, dvalues):\n",
    "        self.dweights = dvalues.T.dot(self.input)\n",
    "        self.dinputs = dvalues.dot(self.weights)\n",
    "    \n",
    "    def update(self):\n",
    "        self.weights += (self.dweights*(-0.001))\n",
    "        # return dvalues.T.dot(self.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredLoss:\n",
    "\n",
    "    def __init__(self, input):\n",
    "        self.input = input\n",
    "    \n",
    "    def forward_propagation(self,input, y_true):\n",
    "        return np.sqrt(((input-y_true)**2).sum()/len(y_true))\n",
    "\n",
    "    def backward_propagation(self,input, y_true):\n",
    "        self.dinputs = -2*(y_true-input)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Dense_layer(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_out = layer.forward_propagation(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = Dense_layer(layer1_out.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_out = layer2.forward_propagation(layer1_out.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MeanSquaredLoss(layer2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.12458689251063"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.forward_propagation(layer2_out,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward_propagation(layer2_out,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.dinputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cur Loss: 0.21846543131470564\n",
      "Cur Loss: 0.21793523913111218\n",
      "Cur Loss: 0.217406333533677\n",
      "Cur Loss: 0.2168787114009826\n",
      "Cur Loss: 0.2163523696191787\n",
      "Cur Loss: 0.21582730508196743\n",
      "Cur Loss: 0.21530351469058567\n",
      "Cur Loss: 0.21478099535377912\n",
      "Cur Loss: 0.2142597439877975\n",
      "Cur Loss: 0.21373975751636407\n",
      "Cur Loss: 0.21322103287066368\n",
      "Cur Loss: 0.21270356698932263\n",
      "Cur Loss: 0.21218735681839362\n",
      "Cur Loss: 0.2116723993113334\n",
      "Cur Loss: 0.2111586914289873\n",
      "Cur Loss: 0.21064623013956982\n",
      "Cur Loss: 0.21013501241865074\n",
      "Cur Loss: 0.20962503524913192\n",
      "Cur Loss: 0.20911629562123324\n",
      "Cur Loss: 0.20860879053247317\n",
      "Cur Loss: 0.20810251698765136\n",
      "Cur Loss: 0.20759747199883194\n",
      "Cur Loss: 0.20709365258532725\n",
      "Cur Loss: 0.20659105577367357\n",
      "Cur Loss: 0.20608967859762167\n",
      "Cur Loss: 0.20558951809811452\n",
      "Cur Loss: 0.2050905713232733\n",
      "Cur Loss: 0.20459283532837508\n",
      "Cur Loss: 0.20409630717583996\n",
      "Cur Loss: 0.20360098393521414\n",
      "Cur Loss: 0.20310686268314745\n",
      "Cur Loss: 0.20261394050338122\n",
      "Cur Loss: 0.20212221448672826\n",
      "Cur Loss: 0.20163168173105644\n",
      "Cur Loss: 0.20114233934127426\n",
      "Cur Loss: 0.20065418442930932\n",
      "Cur Loss: 0.20016721411409544\n",
      "Cur Loss: 0.19968142552155016\n",
      "Cur Loss: 0.19919681578456486\n",
      "Cur Loss: 0.19871338204298333\n",
      "Cur Loss: 0.19823112144358596\n",
      "Cur Loss: 0.1977500311400708\n",
      "Cur Loss: 0.19727010829304148\n",
      "Cur Loss: 0.19679135006998633\n",
      "Cur Loss: 0.19631375364526632\n",
      "Cur Loss: 0.19583731620009104\n",
      "Cur Loss: 0.19536203492250837\n",
      "Cur Loss: 0.19488790700738698\n",
      "Cur Loss: 0.19441492965639756\n",
      "Cur Loss: 0.19394310007799687\n",
      "Cur Loss: 0.19347241548741392\n",
      "Cur Loss: 0.1930028731066295\n",
      "Cur Loss: 0.19253447016436454\n",
      "Cur Loss: 0.19206720389605836\n",
      "Cur Loss: 0.19160107154385672\n",
      "Cur Loss: 0.19113607035659372\n",
      "Cur Loss: 0.19067219758977652\n",
      "Cur Loss: 0.19020945050556692\n",
      "Cur Loss: 0.18974782637276907\n",
      "Cur Loss: 0.18928732246681013\n",
      "Cur Loss: 0.1888279360697248\n",
      "Cur Loss: 0.1883696644701406\n",
      "Cur Loss: 0.18791250496326065\n",
      "Cur Loss: 0.18745645485084855\n",
      "Cur Loss: 0.1870015114412112\n",
      "Cur Loss: 0.18654767204918452\n",
      "Cur Loss: 0.186094933996115\n",
      "Cur Loss: 0.18564329460985124\n",
      "Cur Loss: 0.18519275122471596\n",
      "Cur Loss: 0.1847433011815027\n",
      "Cur Loss: 0.18429494182745065\n",
      "Cur Loss: 0.18384767051623616\n",
      "Cur Loss: 0.18340148460795125\n",
      "Cur Loss: 0.1829563814690922\n",
      "Cur Loss: 0.18251235847254252\n",
      "Cur Loss: 0.18206941299755838\n",
      "Cur Loss: 0.1816275424297498\n",
      "Cur Loss: 0.18118674416107042\n",
      "Cur Loss: 0.18074701558979775\n",
      "Cur Loss: 0.1803083541205198\n",
      "Cur Loss: 0.17987075716412115\n",
      "Cur Loss: 0.17943422213776627\n",
      "Cur Loss: 0.17899874646487954\n",
      "Cur Loss: 0.1785643275751413\n",
      "Cur Loss: 0.17813096290445937\n",
      "Cur Loss: 0.17769864989496584\n",
      "Cur Loss: 0.17726738599499653\n",
      "Cur Loss: 0.17683716865907265\n",
      "Cur Loss: 0.17640799534789295\n",
      "Cur Loss: 0.17597986352831246\n",
      "Cur Loss: 0.17555277067333153\n",
      "Cur Loss: 0.17512671426207993\n",
      "Cur Loss: 0.17470169177980185\n",
      "Cur Loss: 0.17427770071784024\n",
      "Cur Loss: 0.17385473857362213\n",
      "Cur Loss: 0.17343280285064772\n",
      "Cur Loss: 0.17301189105846856\n",
      "Cur Loss: 0.17259200071267886\n",
      "Cur Loss: 0.17217312933489837\n",
      "Cur Loss: 0.1717552744527603\n",
      "Cur Loss: 0.17133843359989132\n",
      "Cur Loss: 0.1709226043159013\n",
      "Cur Loss: 0.17050778414636805\n",
      "Cur Loss: 0.17009397064282317\n",
      "Cur Loss: 0.16968116136273595\n",
      "Cur Loss: 0.16926935386950204\n",
      "Cur Loss: 0.16885854573242648\n",
      "Cur Loss: 0.1684487345267084\n",
      "Cur Loss: 0.16803991783343086\n",
      "Cur Loss: 0.1676320932395405\n",
      "Cur Loss: 0.1672252583378411\n",
      "Cur Loss: 0.1668194107269732\n",
      "Cur Loss: 0.16641454801140246\n",
      "Cur Loss: 0.16601066780140566\n",
      "Cur Loss: 0.16560776771305583\n",
      "Cur Loss: 0.1652058453682053\n",
      "Cur Loss: 0.16480489839447907\n",
      "Cur Loss: 0.16440492442525523\n",
      "Cur Loss: 0.16400592109965215\n",
      "Cur Loss: 0.16360788606251303\n",
      "Cur Loss: 0.16321081696439488\n",
      "Cur Loss: 0.16281471146155732\n",
      "Cur Loss: 0.16241956721593867\n",
      "Cur Loss: 0.16202538189515214\n",
      "Cur Loss: 0.161632153172468\n",
      "Cur Loss: 0.16123987872679996\n",
      "Cur Loss: 0.1608485562426905\n",
      "Cur Loss: 0.16045818341030058\n",
      "Cur Loss: 0.16006875792539313\n",
      "Cur Loss: 0.15968027748932118\n",
      "Cur Loss: 0.15929273980901268\n",
      "Cur Loss: 0.15890614259695648\n",
      "Cur Loss: 0.15852048357119222\n",
      "Cur Loss: 0.15813576045529273\n",
      "Cur Loss: 0.15775197097835636\n",
      "Cur Loss: 0.15736911287498523\n",
      "Cur Loss: 0.15698718388527846\n",
      "Cur Loss: 0.15660618175481944\n",
      "Cur Loss: 0.15622610423465572\n",
      "Cur Loss: 0.15584694908129373\n",
      "Cur Loss: 0.15546871405667884\n",
      "Cur Loss: 0.1550913969281879\n",
      "Cur Loss: 0.154714995468612\n",
      "Cur Loss: 0.15433950745614478\n",
      "Cur Loss: 0.153964930674369\n",
      "Cur Loss: 0.153591262912244\n",
      "Cur Loss: 0.15321850196409492\n",
      "Cur Loss: 0.15284664562959271\n",
      "Cur Loss: 0.15247569171374895\n",
      "Cur Loss: 0.15210563802689683\n",
      "Cur Loss: 0.15173648238468393\n",
      "Cur Loss: 0.1513682226080576\n",
      "Cur Loss: 0.1510008565232449\n",
      "Cur Loss: 0.15063438196175194\n",
      "Cur Loss: 0.15026879676034174\n",
      "Cur Loss: 0.14990409876102817\n",
      "Cur Loss: 0.14954028581105477\n",
      "Cur Loss: 0.14917735576289015\n",
      "Cur Loss: 0.14881530647421193\n",
      "Cur Loss: 0.14845413580789446\n",
      "Cur Loss: 0.14809384163199762\n",
      "Cur Loss: 0.14773442181974922\n",
      "Cur Loss: 0.14737587424954046\n",
      "Cur Loss: 0.1470181968049059\n",
      "Cur Loss: 0.14666138737451545\n",
      "Cur Loss: 0.14630544385215763\n",
      "Cur Loss: 0.14595036413673637\n",
      "Cur Loss: 0.1455961461322475\n",
      "Cur Loss: 0.14524278774777333\n",
      "Cur Loss: 0.1448902868974656\n",
      "Cur Loss: 0.14453864150053966\n",
      "Cur Loss: 0.1441878494812556\n",
      "Cur Loss: 0.1438379087689108\n",
      "Cur Loss: 0.14348881729782284\n",
      "Cur Loss: 0.1431405730073243\n",
      "Cur Loss: 0.14279317384174262\n",
      "Cur Loss: 0.14244661775039635\n",
      "Cur Loss: 0.14210090268757306\n",
      "Cur Loss: 0.14175602661252637\n",
      "Cur Loss: 0.1414119874894602\n",
      "Cur Loss: 0.14106878328751593\n",
      "Cur Loss: 0.14072641198076388\n",
      "Cur Loss: 0.14038487154818488\n",
      "Cur Loss: 0.14004415997366673\n",
      "Cur Loss: 0.1397042752459841\n",
      "Cur Loss: 0.13936521535879165\n",
      "Cur Loss: 0.13902697831061336\n",
      "Cur Loss: 0.1386895621048265\n",
      "Cur Loss: 0.13835296474965203\n",
      "Cur Loss: 0.13801718425814213\n",
      "Cur Loss: 0.1376822186481695\n",
      "Cur Loss: 0.13734806594241633\n",
      "Cur Loss: 0.13701472416836039\n",
      "Cur Loss: 0.13668219135826498\n",
      "Cur Loss: 0.13635046554916683\n",
      "Cur Loss: 0.1360195447828641\n",
      "Cur Loss: 0.1356894271059055\n",
      "Cur Loss: 0.13536011056957903\n",
      "Cur Loss: 0.1350315932298987\n",
      "Cur Loss: 0.13470387314759535\n"
     ]
    }
   ],
   "source": [
    "for _ in range(200):\n",
    "    curloss = loss.forward_propagation(layer2_out,Y)\n",
    "    print(f\"Cur Loss: {curloss}\")\n",
    "    # if loss>last_loss:\n",
    "    #     break\n",
    "    # else:\n",
    "    #     last_loss = loss\n",
    "    layer2.backward_propagation(loss.dinputs.T)\n",
    "    layer.backward_propagation(layer2.dinputs)\n",
    "    layer2.update()\n",
    "    layer.update()\n",
    "    \n",
    "    layer1_out = layer.forward_propagation(X)\n",
    "    layer2_out = layer2.forward_propagation(layer1_out.T)\n",
    "    \n",
    "    loss.backward_propagation(layer2_out,Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_weights = np.random.randn(1,2)\n",
    "t_weights_2 = np.random.rand()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_out(w1,w2):\n",
    "    o1 = X.dot(w1.T)\n",
    "    o2 = o1.dot(w2)\n",
    "    print(o2.shape)\n",
    "    loss = mean_squared_error(Y.T, o2)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n",
      "(100, 1)\n",
      "39690.44658546268\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(50):\n",
    "    cur_loss = cal_out(t_weights, t_weights_2)\n",
    "    print(cur_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.085536923187668"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as nm\n",
    "\n",
    "a = int(input(\"What is the first number?\"))\n",
    "b = int(input(\"What is the second number?\"))\n",
    "\n",
    "np.expm1(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
