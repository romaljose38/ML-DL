{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maping(x):\n",
    "    return x*5 + 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    x = np.random.randint(0,500, 100)\n",
    "    y = sum(list(map(maping, x)))\n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, x, weight,  bias):\n",
    "        self.x = x\n",
    "        self.bias = bias\n",
    "        self.weight = weight\n",
    "\n",
    "    \n",
    "    def get_output(self):\n",
    "        val = self.x * self.weight + self.bias\n",
    "        return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self, input, y, activation):\n",
    "        self.input = input\n",
    "        self.y = y\n",
    "        self.activation = activation\n",
    "        self.weights = np.random.random(len(self.input))\n",
    "        self.bias = np.random.random()\n",
    "    \n",
    "    def output(self):\n",
    "\n",
    "        y_cal = []\n",
    "        \n",
    "        for tensor in self.input:\n",
    "            sum = 0\n",
    "            for idx, val in enumerate(tensor):\n",
    "                p = Perceptron(x=val, weight=self.weights[idx], bias=self.bias)\n",
    "                sum+=p.get_output()\n",
    "            y_cal.append(sum)\n",
    "        \n",
    "        self.y_est = y_cal\n",
    "\n",
    "        return self.y_est\n",
    "\n",
    "    def cal_loss(self):\n",
    "        loss = list(map(lambda x: (x[0]-x[1])**2, zip(self.y_est, self.y)))\n",
    "        \n",
    "        self.cur_loss = loss\n",
    "\n",
    "        return sum(loss)/len(loss)\n",
    "\n",
    "\n",
    "    def propagation(self, step=0.5):\n",
    "\n",
    "        for val in self.input:\n",
    "            \n",
    "            loss = sum(list(map(lambda x: (x[0]-x[1]), zip(self.y_est, self.y))))\n",
    "        \n",
    "            changes = []           \n",
    "            \n",
    "            for idx in range(len(self.y)):\n",
    "                derv = (2*loss/len(self.y_est))*val[idx]\n",
    "                \n",
    "                if derv>0:\n",
    "                    changes.append(self.weights[idx]-(step))\n",
    "                else:\n",
    "                    changes.append(self.weights[idx]+(step))\n",
    "            \n",
    "\n",
    "            self.weights=changes\n",
    "\n",
    "            self.output()\n",
    "            self.cal_loss()        \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Layer(input=X, y=Y,activation=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12643.595235730056,\n",
       " 13308.95682141238,\n",
       " 12874.039615162854,\n",
       " 13023.346675145553,\n",
       " 14189.908175399527,\n",
       " 14125.876096362408,\n",
       " 13130.71842525306,\n",
       " 12437.664135875806,\n",
       " 13887.280781852447,\n",
       " 12297.67332812356,\n",
       " 12999.007625172035,\n",
       " 13748.64545109412,\n",
       " 11780.3848366759,\n",
       " 13161.080979089544,\n",
       " 11321.696039940942,\n",
       " 12284.83943879833,\n",
       " 12042.895541693344,\n",
       " 12096.922091268883,\n",
       " 13158.557182567656,\n",
       " 12928.880559510428,\n",
       " 13050.951463263858,\n",
       " 13070.24823317685,\n",
       " 13367.255688210045,\n",
       " 13846.852049103936,\n",
       " 14691.559685957109,\n",
       " 12272.136266429598,\n",
       " 13068.38615784415,\n",
       " 13072.700616823417,\n",
       " 11481.226794927927,\n",
       " 12835.101357841426,\n",
       " 13538.978281878282,\n",
       " 12830.114023848473,\n",
       " 11842.23069562788,\n",
       " 13365.017496612492,\n",
       " 13041.023798718867,\n",
       " 13703.594447649075,\n",
       " 13235.48179551833,\n",
       " 11703.271297781737,\n",
       " 11942.450450374265,\n",
       " 13091.649014438954,\n",
       " 12590.420858533515,\n",
       " 10570.7645438797,\n",
       " 13954.814066480676,\n",
       " 12233.392851249693,\n",
       " 11699.76145751159,\n",
       " 11840.350153928139,\n",
       " 12610.971528399883,\n",
       " 11484.567134495801,\n",
       " 12521.07401612271,\n",
       " 11684.159501691076,\n",
       " 14192.033745381752,\n",
       " 11685.075153914991,\n",
       " 12645.14346779401,\n",
       " 12656.065485245472,\n",
       " 13029.710552074543,\n",
       " 12631.780713880142,\n",
       " 11726.479871128939,\n",
       " 11715.0146977389,\n",
       " 13088.394286159408,\n",
       " 12717.878338431108,\n",
       " 12571.69325195988,\n",
       " 10806.092040040872,\n",
       " 12927.94475312348,\n",
       " 11259.6167839099,\n",
       " 12084.127713942125,\n",
       " 12475.143478269447,\n",
       " 12545.41912591932,\n",
       " 12864.185009778754,\n",
       " 11835.396375192173,\n",
       " 13304.523589388953,\n",
       " 13607.472427731753,\n",
       " 13019.049652262544,\n",
       " 13318.773277278282,\n",
       " 11945.322300395455,\n",
       " 12243.921177082706,\n",
       " 12019.0293740244,\n",
       " 11649.451536655508,\n",
       " 12396.761709305592,\n",
       " 13680.103353276669,\n",
       " 11036.01815385151,\n",
       " 11918.524336272758,\n",
       " 12687.311688997,\n",
       " 12120.788369428965,\n",
       " 12754.616545937522,\n",
       " 11585.373142684477,\n",
       " 13354.434709281979,\n",
       " 11216.832989916646,\n",
       " 13641.12522765311,\n",
       " 12187.657843588007,\n",
       " 11471.9401863183,\n",
       " 13860.978106201675,\n",
       " 12233.642610315344,\n",
       " 12957.027036695841,\n",
       " 12327.891112122961,\n",
       " 13816.5764120565,\n",
       " 11335.957761095688,\n",
       " 13316.299850445206,\n",
       " 13225.187396308107,\n",
       " 12376.588365860069,\n",
       " 10571.367878271141]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12878513604.80053"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.cal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98433312, 0.22976907, 0.36448183, 0.23071664, 0.64844951,\n",
       "       0.06095792, 0.09584023, 0.39737928, 0.53552435, 0.79230923,\n",
       "       0.02599366, 0.3892033 , 0.5120824 , 0.56254055, 0.60174865,\n",
       "       0.55461945, 0.3999683 , 0.80145891, 0.61913764, 0.15529305,\n",
       "       0.87263359, 0.18463628, 0.45740352, 0.24288024, 0.2297728 ,\n",
       "       0.76088146, 0.11940842, 0.30374409, 0.47561219, 0.69017044,\n",
       "       0.18352056, 0.97794789, 0.27760113, 0.47287677, 0.79018299,\n",
       "       0.65928254, 0.16879321, 0.47982652, 0.8197435 , 0.20991943,\n",
       "       0.74171279, 0.32235947, 0.79885562, 0.79592047, 0.49196644,\n",
       "       0.93234933, 0.93355463, 0.78816153, 0.47749042, 0.67419002,\n",
       "       0.8973716 , 0.25807436, 0.49042619, 0.94348001, 0.47055354,\n",
       "       0.05185675, 0.31375008, 0.09637078, 0.98463878, 0.91580042,\n",
       "       0.31731853, 0.24015416, 0.99726706, 0.68054162, 0.03984902,\n",
       "       0.46398628, 0.19812458, 0.02761466, 0.79505188, 0.97538016,\n",
       "       0.81839801, 0.7214509 , 0.06974588, 0.9860057 , 0.7906794 ,\n",
       "       0.24349578, 0.10392709, 0.83690975, 0.29517555, 0.70003411,\n",
       "       0.60553269, 0.98133458, 0.79653707, 0.26550766, 0.324362  ,\n",
       "       0.10309568, 0.43618129, 0.61973997, 0.72889474, 0.14085551,\n",
       "       0.39199665, 0.34402711, 0.35402897, 0.80497993, 0.92024047,\n",
       "       0.08918828, 0.53614195, 0.40917949, 0.09482331, 0.35097685])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92380986.11569908"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.cal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630394001.6952511"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.cal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 0\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    l1.propagation()\n",
    "\n",
    "    loss = l1.cal_loss()\n",
    "\n",
    "    if min<loss:\n",
    "        min = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073279300.1111346"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    step = trial.suggest_float(\"step\", 0.1, 1, step=0.05)\n",
    "    l1.propagation(step=step)\n",
    "    loss = l1.cal_loss()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 23:09:28,819]\u001b[0m A new study created in memory with name: no-name-0b9df0b9-e3f5-412a-b9d8-19b809158d46\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:29,508]\u001b[0m Trial 0 finished with value: 390902303.87756324 and parameters: {'step': 0.85}. Best is trial 0 with value: 390902303.87756324.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:30,205]\u001b[0m Trial 1 finished with value: 1611584.1175215137 and parameters: {'step': 0.45000000000000007}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:30,890]\u001b[0m Trial 2 finished with value: 26046988.91219394 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:31,574]\u001b[0m Trial 3 finished with value: 7576981.207246948 and parameters: {'step': 0.15000000000000002}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:32,265]\u001b[0m Trial 4 finished with value: 15287016.730882114 and parameters: {'step': 0.85}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:32,951]\u001b[0m Trial 5 finished with value: 39307862.88485852 and parameters: {'step': 0.4}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:33,639]\u001b[0m Trial 6 finished with value: 128852521.64401124 and parameters: {'step': 0.8}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:34,323]\u001b[0m Trial 7 finished with value: 284626961.62541103 and parameters: {'step': 0.85}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:35,003]\u001b[0m Trial 8 finished with value: 263372495.70985165 and parameters: {'step': 0.7000000000000001}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:35,702]\u001b[0m Trial 9 finished with value: 41747417.1318382 and parameters: {'step': 0.35}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:36,401]\u001b[0m Trial 10 finished with value: 90342274.30475588 and parameters: {'step': 0.55}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:37,080]\u001b[0m Trial 11 finished with value: 32939608.158374798 and parameters: {'step': 0.1}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:37,759]\u001b[0m Trial 12 finished with value: 31666733.484426595 and parameters: {'step': 0.1}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:38,450]\u001b[0m Trial 13 finished with value: 30353147.276981983 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:39,120]\u001b[0m Trial 14 finished with value: 49624564.39999594 and parameters: {'step': 0.55}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:39,808]\u001b[0m Trial 15 finished with value: 150988343.21693704 and parameters: {'step': 1.0}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:40,491]\u001b[0m Trial 16 finished with value: 52564791.70702527 and parameters: {'step': 0.25}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:41,187]\u001b[0m Trial 17 finished with value: 53434854.0810011 and parameters: {'step': 0.4}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:41,880]\u001b[0m Trial 18 finished with value: 59181157.47078929 and parameters: {'step': 0.2}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:42,573]\u001b[0m Trial 19 finished with value: 88678205.79725981 and parameters: {'step': 0.5}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:43,261]\u001b[0m Trial 20 finished with value: 159340480.51987144 and parameters: {'step': 0.65}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:43,946]\u001b[0m Trial 21 finished with value: 339384895.9888121 and parameters: {'step': 1.0}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:44,619]\u001b[0m Trial 22 finished with value: 105699036.73285037 and parameters: {'step': 0.2}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:45,306]\u001b[0m Trial 23 finished with value: 96794061.59868336 and parameters: {'step': 0.45000000000000007}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:45,982]\u001b[0m Trial 24 finished with value: 110076210.65275715 and parameters: {'step': 0.65}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:46,658]\u001b[0m Trial 25 finished with value: 191421507.13760358 and parameters: {'step': 0.9}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:47,334]\u001b[0m Trial 26 finished with value: 124811957.65407497 and parameters: {'step': 0.2}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:48,015]\u001b[0m Trial 27 finished with value: 154482294.14190614 and parameters: {'step': 0.6}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:48,709]\u001b[0m Trial 28 finished with value: 180453172.8821883 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:49,388]\u001b[0m Trial 29 finished with value: 305056646.36063486 and parameters: {'step': 0.9}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:50,060]\u001b[0m Trial 30 finished with value: 249670169.8647951 and parameters: {'step': 0.45000000000000007}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:50,746]\u001b[0m Trial 31 finished with value: 204556962.54918328 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:51,439]\u001b[0m Trial 32 finished with value: 182928484.7435714 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:52,122]\u001b[0m Trial 33 finished with value: 194464466.20880696 and parameters: {'step': 0.85}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:52,803]\u001b[0m Trial 34 finished with value: 254113794.64351228 and parameters: {'step': 0.75}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:53,478]\u001b[0m Trial 35 finished with value: 389892889.99435866 and parameters: {'step': 0.9}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:54,169]\u001b[0m Trial 36 finished with value: 513768854.34986573 and parameters: {'step': 0.65}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:54,845]\u001b[0m Trial 37 finished with value: 402439343.44855744 and parameters: {'step': 0.9500000000000001}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:55,521]\u001b[0m Trial 38 finished with value: 337913617.54177123 and parameters: {'step': 0.8}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:56,203]\u001b[0m Trial 39 finished with value: 300108294.98858523 and parameters: {'step': 0.8}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:56,884]\u001b[0m Trial 40 finished with value: 288947718.6305477 and parameters: {'step': 0.7000000000000001}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:57,564]\u001b[0m Trial 41 finished with value: 293104366.93319654 and parameters: {'step': 0.35}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:58,247]\u001b[0m Trial 42 finished with value: 307163311.4738788 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:58,949]\u001b[0m Trial 43 finished with value: 308641123.937515 and parameters: {'step': 0.1}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:59,630]\u001b[0m Trial 44 finished with value: 308964207.3825221 and parameters: {'step': 0.4}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:00,310]\u001b[0m Trial 45 finished with value: 321194044.22028494 and parameters: {'step': 0.25}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:00,990]\u001b[0m Trial 46 finished with value: 329876290.8600259 and parameters: {'step': 0.15000000000000002}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:01,666]\u001b[0m Trial 47 finished with value: 372867596.42649615 and parameters: {'step': 0.5}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:02,359]\u001b[0m Trial 48 finished with value: 400762746.2766291 and parameters: {'step': 0.30000000000000004}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:03,036]\u001b[0m Trial 49 finished with value: 353901294.0313941 and parameters: {'step': 0.15000000000000002}. Best is trial 1 with value: 1611584.1175215137.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tuner = optuna.create_study(direction=\"minimize\")\n",
    "tuner.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125240,\n",
       " 133500,\n",
       " 129895,\n",
       " 127875,\n",
       " 142695,\n",
       " 136525,\n",
       " 127665,\n",
       " 123250,\n",
       " 133905,\n",
       " 122060,\n",
       " 126120,\n",
       " 133695,\n",
       " 110430,\n",
       " 135155,\n",
       " 113275,\n",
       " 120765,\n",
       " 121165,\n",
       " 121400,\n",
       " 123540,\n",
       " 124010,\n",
       " 126645,\n",
       " 131780,\n",
       " 138985,\n",
       " 131990,\n",
       " 140235,\n",
       " 122460,\n",
       " 128535,\n",
       " 131940,\n",
       " 114565,\n",
       " 126205,\n",
       " 131450,\n",
       " 128650,\n",
       " 118015,\n",
       " 131580,\n",
       " 125565,\n",
       " 139580,\n",
       " 131870,\n",
       " 121490,\n",
       " 118830,\n",
       " 131050,\n",
       " 126810,\n",
       " 111705,\n",
       " 132955,\n",
       " 125880,\n",
       " 114820,\n",
       " 119090,\n",
       " 126510,\n",
       " 113440,\n",
       " 135910,\n",
       " 123155,\n",
       " 140720,\n",
       " 115115,\n",
       " 129670,\n",
       " 126970,\n",
       " 131990,\n",
       " 125120,\n",
       " 115540,\n",
       " 119095,\n",
       " 126640,\n",
       " 124995,\n",
       " 121260,\n",
       " 107900,\n",
       " 132590,\n",
       " 118025,\n",
       " 123860,\n",
       " 125510,\n",
       " 123765,\n",
       " 132690,\n",
       " 118635,\n",
       " 132965,\n",
       " 133575,\n",
       " 130035,\n",
       " 121235,\n",
       " 126965,\n",
       " 118060,\n",
       " 116865,\n",
       " 117995,\n",
       " 119815,\n",
       " 136915,\n",
       " 112260,\n",
       " 127940,\n",
       " 128915,\n",
       " 124565,\n",
       " 122525,\n",
       " 122675,\n",
       " 127740,\n",
       " 117130,\n",
       " 136805,\n",
       " 120660,\n",
       " 117525,\n",
       " 134455,\n",
       " 122045,\n",
       " 132250,\n",
       " 122360,\n",
       " 137515,\n",
       " 119425,\n",
       " 134305,\n",
       " 133675,\n",
       " 128895,\n",
       " 116445]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01057901486696921"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1611584**(1/2))/120000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
